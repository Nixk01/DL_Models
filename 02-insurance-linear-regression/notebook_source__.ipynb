{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "h2ADRanRyxkN"
   },
   "source": [
    "# Insurance cost prediction using linear regression\n",
    "\n",
    "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n",
    "\n",
    "\n",
    "We will create a model with the following steps:\n",
    "1. Download and explore the dataset\n",
    "2. Prepare the dataset for training\n",
    "3. Create a linear regression model\n",
    "4. Train the model to fit the data\n",
    "5. Make predictions using the trained model\n",
    "\n",
    "\n",
    "This assignment builds upon the concepts from the first 2 lectures. It will help to review these Jupyter notebooks:\n",
    "- PyTorch basics: https://jovian.ml/aakashns/01-pytorch-basics\n",
    "- Linear Regression: https://jovian.ml/aakashns/02-linear-regression\n",
    "- Logistic Regression: https://jovian.ml/aakashns/03-logistic-regression\n",
    "- Linear regression (minimal): https://jovian.ml/aakashns/housing-linear-minimal\n",
    "- Logistic regression (minimal): https://jovian.ml/aakashns/mnist-logistic-minimal\n",
    "\n",
    "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kYrRDUSvyxkR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment and run the commands below if imports fail\n",
    "#!conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
    "#!pip install matplotlib --upgrade --quiet\n",
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UB3pAOKhyxlP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import jovian\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4gQmFVXcyxla"
   },
   "outputs": [],
   "source": [
    "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzqNcSsVyxlm"
   },
   "source": [
    "## Step 1: Download and explore the data\n",
    "\n",
    "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "W-Ud1QCIyxln"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./insurance.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_qIlWWnyxl0"
   },
   "source": [
    "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "soaODDCQyxl1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-output": true,
    "id": "RW_46Xhm3AQy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Jqyqk8Tyxl-"
   },
   "source": [
    "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iOuMa_QLyxl_"
   },
   "outputs": [],
   "source": [
    "your_name = 'Nikuj' # at least 5 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBBShChRyxmI"
   },
   "source": [
    "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Yiofl4A1yxmK"
   },
   "outputs": [],
   "source": [
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows\n",
    "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['region'], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zooR92vxyxmT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.shape#Use Shape Function of Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QUbti5wWVfBW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>42</td>\n",
       "      <td>female</td>\n",
       "      <td>27.93000</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>22843.115420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>42</td>\n",
       "      <td>female</td>\n",
       "      <td>34.51350</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>7543.522791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>54</td>\n",
       "      <td>male</td>\n",
       "      <td>31.72050</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>10947.704893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>59</td>\n",
       "      <td>male</td>\n",
       "      <td>30.22425</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>12978.687140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>25.83525</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>5625.533506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex       bmi  children smoker       charges\n",
       "160    42  female  27.93000         0    yes  22843.115420\n",
       "1326   42  female  34.51350         0     no   7543.522791\n",
       "544    54    male  31.72050         0     no  10947.704893\n",
       "624    59    male  30.22425         0     no  12978.687140\n",
       "914    33    male  25.83525         2     no   5625.533506"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQHRioy5yxmf"
   },
   "source": [
    "Let us answer some basic questions about the dataset. \n",
    "\n",
    "\n",
    "**Q: How many rows does the dataset have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "id": "-Nfou6_Myxmh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "num_rows = dataframe.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0hmuEF9yxmo"
   },
   "source": [
    "**Q: How many columns doe the dataset have**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Ida9L0Lyyxmp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "num_cols = dataframe.shape[1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRrAvf3eyxmx"
   },
   "source": [
    "**Q:What are the column titles of the input variables?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "lYh_kqfByxmz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'children', 'smoker']\n"
     ]
    }
   ],
   "source": [
    "input_cols = dataframe.columns[:5].tolist()\n",
    "print(input_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa2fcsdMyxm6"
   },
   "source": [
    "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
    "\n",
    "Hint: `sex` is one of them. List the columns that are not numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "uCDOHPFVyxm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'smoker']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = dataframe.select_dtypes(exclude='number').columns.tolist()\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG8gsvH7yxnC"
   },
   "source": [
    "**Q: What are the column titles of output/target variable**\n",
    "\n",
    "\n",
    "*   charges\n",
    "\n",
    "(s)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "mBwIXp9ZyxnD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charges']\n"
     ]
    }
   ],
   "source": [
    "output_cols = [dataframe.columns[5]]\n",
    "print(output_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQidgegeyxnO"
   },
   "source": [
    "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
    "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "id": "qRNziHXcyxnQ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mi=1200.40\n",
    "ma=68234.36\n",
    "avg=14147.54\n",
    "\n",
    "labels = 'Minimum', 'Max', 'Average'\n",
    "sizes = [mi,ma, avg]\n",
    "explode = (0, 0.3, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "id": "sYitsT7XUAkb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1271.000000\n",
       "mean     14147.538758\n",
       "std      12890.170390\n",
       "min       1200.405073\n",
       "25%       5078.967341\n",
       "50%      10043.192591\n",
       "75%      17672.915732\n",
       "max      68234.357971\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['charges'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUgObGSzyxnW"
   },
   "source": [
    "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Qkgu_hCeUBUo"
   },
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "id": "41oi0V8CyxnY"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\n",
      "API KEY: ········\n",
      "[jovian] Updating notebook \"nixkjadhav007/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/nixkjadhav007/02-insurance-linear-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/nixkjadhav007/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 2: Prepare the dataset for training**\n",
    "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out input_cols, categorial_cols and output_cols correctly, this following function will perform the conversion to numpy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDIgZpKryxoS"
   },
   "source": [
    "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "id": "_QjSp0b_yxoT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[42.     ,  0.     , 27.93   ,  0.     ,  1.     ],\n",
       "        [42.     ,  0.     , 34.5135 ,  0.     ,  0.     ],\n",
       "        [54.     ,  1.     , 31.7205 ,  0.     ,  0.     ],\n",
       "        ...,\n",
       "        [40.     ,  0.     , 26.733  ,  1.     ,  0.     ],\n",
       "        [55.     ,  1.     , 39.60075,  3.     ,  0.     ],\n",
       "        [36.     ,  1.     , 29.42625,  1.     ,  1.     ]]),\n",
       " array([[22843.11542  ],\n",
       "        [ 7543.522791 ],\n",
       "        [10947.704893 ],\n",
       "        ...,\n",
       "        [ 7572.592658 ],\n",
       "        [32168.0311885],\n",
       "        [22227.7816925]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyJwR_Gyyxob"
   },
   "source": [
    "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "KWu1-MQyyxod"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42.0000,  0.0000, 27.9300,  0.0000,  1.0000],\n",
       "        [42.0000,  0.0000, 34.5135,  0.0000,  0.0000],\n",
       "        [54.0000,  1.0000, 31.7205,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [40.0000,  0.0000, 26.7330,  1.0000,  0.0000],\n",
       "        [55.0000,  1.0000, 39.6007,  3.0000,  0.0000],\n",
       "        [36.0000,  1.0000, 29.4263,  1.0000,  1.0000]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor(inputs_array, dtype = torch.float32)\n",
    "targets = torch.tensor(targets_array, dtype = torch.float32)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Gn0V8_t0yxoq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tBOmf9ryxpN"
   },
   "source": [
    "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ketudq9KyxpO"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "id": "JZpqbxb0kRFO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22843.1152],\n",
       "        [ 7543.5229],\n",
       "        [10947.7051],\n",
       "        ...,\n",
       "        [ 7572.5928],\n",
       "        [32168.0312],\n",
       "        [22227.7812]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3t96vtMyxpl"
   },
   "source": [
    "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "id": "dB2dEm1lyxpn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f6bc445f810>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_percent = 0.2 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "train_ds, val_ds =  random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "U2-9G5UOd0Jp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f6bd011fe50>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMv_7fScyxp7"
   },
   "source": [
    "Finally, we can create data loaders for training & validation.\n",
    "\n",
    "**Q: Pick a batch size for the data loader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "-sPCHQUtyxp8"
   },
   "outputs": [],
   "source": [
    "batch_size = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "eqjuBHI3yxqL"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "cLaOEpqim06r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f6bc444d210>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgzlmIg2yxqi"
   },
   "source": [
    "Let's look at a batch of data to verify everything is working fine so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "id": "rAR4IOAmyxqj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[18.0000,  1.0000, 36.9600,  1.0000,  0.0000],\n",
      "        [50.0000,  1.0000, 32.5185,  3.0000,  0.0000],\n",
      "        [42.0000,  1.0000, 35.8050,  0.0000,  0.0000],\n",
      "        [22.0000,  1.0000, 38.9235,  2.0000,  1.0000],\n",
      "        [31.0000,  1.0000, 31.3005,  0.0000,  1.0000],\n",
      "        [59.0000,  0.0000, 27.8302,  0.0000,  0.0000],\n",
      "        [19.0000,  0.0000, 33.7155,  0.0000,  0.0000],\n",
      "        [64.0000,  0.0000, 41.0025,  3.0000,  0.0000],\n",
      "        [25.0000,  0.0000, 43.3913,  0.0000,  0.0000],\n",
      "        [35.0000,  0.0000, 36.5400,  1.0000,  0.0000],\n",
      "        [45.0000,  1.0000, 28.8750,  3.0000,  0.0000],\n",
      "        [44.0000,  0.0000, 26.2500,  1.0000,  0.0000],\n",
      "        [44.0000,  1.0000, 33.6157,  2.0000,  0.0000],\n",
      "        [26.0000,  1.0000, 18.5535,  0.0000,  0.0000],\n",
      "        [20.0000,  0.0000, 25.6410,  0.0000,  1.0000],\n",
      "        [43.0000,  0.0000, 25.9350,  2.0000,  1.0000],\n",
      "        [45.0000,  0.0000, 38.1150,  2.0000,  0.0000],\n",
      "        [50.0000,  1.0000, 33.8153,  0.0000,  0.0000],\n",
      "        [32.0000,  0.0000, 21.5460,  0.0000,  0.0000],\n",
      "        [19.0000,  1.0000, 31.9200,  0.0000,  0.0000],\n",
      "        [32.0000,  1.0000, 29.5260,  4.0000,  1.0000],\n",
      "        [48.0000,  1.0000, 38.5035,  1.0000,  0.0000],\n",
      "        [21.0000,  0.0000, 35.3115,  2.0000,  0.0000],\n",
      "        [35.0000,  1.0000, 30.3450,  3.0000,  0.0000],\n",
      "        [53.0000,  0.0000, 37.6950,  2.0000,  0.0000],\n",
      "        [36.0000,  0.0000, 31.4160,  0.0000,  0.0000],\n",
      "        [29.0000,  0.0000, 27.3315,  0.0000,  0.0000],\n",
      "        [23.0000,  0.0000, 44.8875,  1.0000,  1.0000],\n",
      "        [33.0000,  1.0000, 44.5830,  1.0000,  0.0000],\n",
      "        [47.0000,  0.0000, 37.8000,  1.0000,  0.0000],\n",
      "        [36.0000,  1.0000, 30.0247,  3.0000,  0.0000],\n",
      "        [62.0000,  0.0000, 39.9997,  2.0000,  0.0000],\n",
      "        [58.0000,  1.0000, 26.4338,  0.0000,  0.0000],\n",
      "        [37.0000,  1.0000, 48.8565,  3.0000,  0.0000],\n",
      "        [54.0000,  1.0000, 42.5933,  3.0000,  1.0000],\n",
      "        [47.0000,  0.0000, 29.2215,  0.0000,  1.0000],\n",
      "        [27.0000,  1.0000, 24.2550,  0.0000,  0.0000],\n",
      "        [44.0000,  0.0000, 40.8975,  0.0000,  1.0000]])\n",
      "targets: tensor([[ 1848.4678],\n",
      "        [11342.5869],\n",
      "        [ 6398.3120],\n",
      "        [40108.3594],\n",
      "        [20704.8945],\n",
      "        [13712.5264],\n",
      "        [ 2279.8232],\n",
      "        [17211.0859],\n",
      "        [19130.4238],\n",
      "        [ 5613.2705],\n",
      "        [ 9218.3711],\n",
      "        [ 8157.1641],\n",
      "        [ 8684.4072],\n",
      "        [ 2868.6157],\n",
      "        [27954.4727],\n",
      "        [23412.4766],\n",
      "        [ 9124.4590],\n",
      "        [ 9453.7334],\n",
      "        [ 4862.3311],\n",
      "        [ 1344.2400],\n",
      "        [22975.5527],\n",
      "        [30461.7441],\n",
      "        [ 3830.4167],\n",
      "        [ 6341.7251],\n",
      "        [11945.0176],\n",
      "        [ 5231.2695],\n",
      "        [ 3998.0173],\n",
      "        [43767.4922],\n",
      "        [12119.5850],\n",
      "        [ 9155.8906],\n",
      "        [ 7006.5688],\n",
      "        [16296.4463],\n",
      "        [12766.3037],\n",
      "        [ 6886.1172],\n",
      "        [51947.6211],\n",
      "        [24680.0000],\n",
      "        [ 2657.5974],\n",
      "        [45992.3008]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb)\n",
    "    print(\"targets:\", yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8x8m-uzyxqq"
   },
   "source": [
    "Let's save our work by committing to Jovian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "id": "7YIYnMn2yxqr"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"nixkjadhav007/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/nixkjadhav007/02-insurance-linear-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/nixkjadhav007/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8khc-kSbyxqv"
   },
   "source": [
    "## Step 3: Create a Linear Regression Model\n",
    "\n",
    "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "BwCey7LaVm3m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4558],\n",
       "        [-0.9476],\n",
       "        [ 2.2902],\n",
       "        [-1.2088],\n",
       "        [ 0.3664],\n",
       "        [-1.8225]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "4qHVxDrryxqw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charges']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)\n",
    "output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOdTp6--yxq1"
   },
   "source": [
    "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
    "\n",
    "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "TZgc6yu5yxq4"
   },
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear =  nn.Linear(input_size, output_size)      # fill this (hint: use input_size & output_size defined above)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out =  self.linear(xb)                       # fill this\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.smooth_l1_loss(out, targets)                          # fill this\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.smooth_l1_loss(out, targets)                           # fill this    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpl7e1rgyxq-"
   },
   "source": [
    "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "JFAfz3H0yxq_"
   },
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odQ_00g0yxrD"
   },
   "source": [
    "Let's check out the weights and biases of the model using `model.parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "id": "PH4ioCHSyxrE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3287,  0.1354,  0.0618,  0.2910,  0.1737]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3751], requires_grad=True)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebDIBptRyxrM"
   },
   "source": [
    "One final commit before we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "id": "XE69yI9lyxrN"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"nixkjadhav007/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/nixkjadhav007/02-insurance-linear-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/nixkjadhav007/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZR5Cf36yxrR"
   },
   "source": [
    "## Step 4: Train the model to fit the data\n",
    "\n",
    "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "aNOCGyKYyxrS"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8scu0bzyxrX"
   },
   "source": [
    "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "-rA6YCq1yxrY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 14141.197265625}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, val_loader)# Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ETLR9rvyxrg"
   },
   "source": [
    "\n",
    "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR2bWaiPyxri"
   },
   "source": [
    "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
    "\n",
    "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "C4Lw3GnIyxrj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7163.3350\n",
      "Epoch [40], val_loss: 7152.0522\n",
      "Epoch [60], val_loss: 7147.1841\n",
      "Epoch [80], val_loss: 7144.3491\n",
      "Epoch [100], val_loss: 7142.5654\n",
      "Epoch [120], val_loss: 7143.1323\n",
      "Epoch [140], val_loss: 7145.0981\n",
      "Epoch [160], val_loss: 7145.3315\n",
      "Epoch [180], val_loss: 7145.8169\n",
      "Epoch [200], val_loss: 7146.3062\n",
      "Epoch [220], val_loss: 7146.9375\n",
      "Epoch [240], val_loss: 7146.9961\n",
      "Epoch [260], val_loss: 7147.0747\n",
      "Epoch [280], val_loss: 7147.0034\n",
      "Epoch [300], val_loss: 7146.8662\n",
      "Epoch [320], val_loss: 7146.6572\n",
      "Epoch [340], val_loss: 7146.2812\n",
      "Epoch [360], val_loss: 7145.7197\n",
      "Epoch [380], val_loss: 7145.2148\n",
      "Epoch [400], val_loss: 7144.9194\n",
      "Epoch [420], val_loss: 7144.1562\n",
      "Epoch [440], val_loss: 7143.4639\n",
      "Epoch [460], val_loss: 7142.8330\n",
      "Epoch [480], val_loss: 7141.9307\n",
      "Epoch [500], val_loss: 7141.2007\n",
      "Epoch [520], val_loss: 7140.4653\n",
      "Epoch [540], val_loss: 7139.5728\n",
      "Epoch [560], val_loss: 7139.4390\n",
      "Epoch [580], val_loss: 7138.5747\n",
      "Epoch [600], val_loss: 7137.5259\n",
      "Epoch [620], val_loss: 7136.7075\n",
      "Epoch [640], val_loss: 7136.3755\n",
      "Epoch [660], val_loss: 7135.4897\n",
      "Epoch [680], val_loss: 7134.6943\n",
      "Epoch [700], val_loss: 7133.6885\n",
      "Epoch [720], val_loss: 7133.2651\n",
      "Epoch [740], val_loss: 7132.5532\n",
      "Epoch [760], val_loss: 7131.6875\n",
      "Epoch [780], val_loss: 7131.1753\n",
      "Epoch [800], val_loss: 7130.2266\n",
      "Epoch [820], val_loss: 7129.4834\n",
      "Epoch [840], val_loss: 7128.7422\n",
      "Epoch [860], val_loss: 7128.5361\n",
      "Epoch [880], val_loss: 7127.3477\n",
      "Epoch [900], val_loss: 7127.0337\n",
      "Epoch [920], val_loss: 7126.5322\n",
      "Epoch [940], val_loss: 7126.2739\n",
      "Epoch [960], val_loss: 7125.6831\n",
      "Epoch [980], val_loss: 7124.8320\n",
      "Epoch [1000], val_loss: 7124.2896\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 1e-2   \n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "VRsriJlvyxro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7124.2817\n",
      "Epoch [40], val_loss: 7124.2749\n",
      "Epoch [60], val_loss: 7124.2681\n",
      "Epoch [80], val_loss: 7124.2661\n",
      "Epoch [100], val_loss: 7124.2617\n",
      "Epoch [120], val_loss: 7124.2554\n",
      "Epoch [140], val_loss: 7124.2466\n",
      "Epoch [160], val_loss: 7124.2378\n",
      "Epoch [180], val_loss: 7124.2354\n",
      "Epoch [200], val_loss: 7124.2300\n",
      "Epoch [220], val_loss: 7124.2236\n",
      "Epoch [240], val_loss: 7124.2222\n",
      "Epoch [260], val_loss: 7124.2163\n",
      "Epoch [280], val_loss: 7124.2085\n",
      "Epoch [300], val_loss: 7124.1992\n",
      "Epoch [320], val_loss: 7124.1953\n",
      "Epoch [340], val_loss: 7124.1890\n",
      "Epoch [360], val_loss: 7124.1836\n",
      "Epoch [380], val_loss: 7124.1758\n",
      "Epoch [400], val_loss: 7124.1704\n",
      "Epoch [420], val_loss: 7124.1709\n",
      "Epoch [440], val_loss: 7124.1685\n",
      "Epoch [460], val_loss: 7124.1631\n",
      "Epoch [480], val_loss: 7124.1528\n",
      "Epoch [500], val_loss: 7124.1509\n",
      "Epoch [520], val_loss: 7124.1455\n",
      "Epoch [540], val_loss: 7124.1357\n",
      "Epoch [560], val_loss: 7124.1289\n",
      "Epoch [580], val_loss: 7124.1279\n",
      "Epoch [600], val_loss: 7124.1226\n",
      "Epoch [620], val_loss: 7124.1128\n",
      "Epoch [640], val_loss: 7124.1055\n",
      "Epoch [660], val_loss: 7124.0972\n",
      "Epoch [680], val_loss: 7124.0952\n",
      "Epoch [700], val_loss: 7124.0903\n",
      "Epoch [720], val_loss: 7124.0869\n",
      "Epoch [740], val_loss: 7124.0791\n",
      "Epoch [760], val_loss: 7124.0732\n",
      "Epoch [780], val_loss: 7124.0688\n",
      "Epoch [800], val_loss: 7124.0625\n",
      "Epoch [820], val_loss: 7124.0557\n",
      "Epoch [840], val_loss: 7124.0518\n",
      "Epoch [860], val_loss: 7124.0439\n",
      "Epoch [880], val_loss: 7124.0454\n",
      "Epoch [900], val_loss: 7124.0376\n",
      "Epoch [920], val_loss: 7124.0308\n",
      "Epoch [940], val_loss: 7124.0303\n",
      "Epoch [960], val_loss: 7124.0234\n",
      "Epoch [980], val_loss: 7124.0225\n",
      "Epoch [1000], val_loss: 7124.0181\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 1e-4\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "7XungUYJyxrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7124.0186\n",
      "Epoch [40], val_loss: 7124.0190\n",
      "Epoch [60], val_loss: 7124.0186\n",
      "Epoch [80], val_loss: 7124.0190\n",
      "Epoch [100], val_loss: 7124.0190\n",
      "Epoch [120], val_loss: 7124.0190\n",
      "Epoch [140], val_loss: 7124.0190\n",
      "Epoch [150], val_loss: 7124.0190\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "lr = 1e-6\n",
    "history3 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "eosG5Vz4yxr0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7123.9946\n",
      "Epoch [40], val_loss: 7123.9219\n",
      "Epoch [60], val_loss: 7123.8511\n",
      "Epoch [80], val_loss: 7123.8047\n",
      "Epoch [100], val_loss: 7123.7393\n",
      "Epoch [120], val_loss: 7123.7373\n",
      "Epoch [140], val_loss: 7123.6499\n",
      "Epoch [160], val_loss: 7123.6099\n",
      "Epoch [180], val_loss: 7123.5757\n",
      "Epoch [200], val_loss: 7123.4956\n",
      "Epoch [220], val_loss: 7123.4561\n",
      "Epoch [240], val_loss: 7123.4507\n",
      "Epoch [260], val_loss: 7123.3545\n",
      "Epoch [280], val_loss: 7123.3345\n",
      "Epoch [300], val_loss: 7123.2661\n",
      "Epoch [320], val_loss: 7123.2231\n",
      "Epoch [340], val_loss: 7123.1963\n",
      "Epoch [360], val_loss: 7123.0938\n",
      "Epoch [380], val_loss: 7123.0669\n",
      "Epoch [400], val_loss: 7123.0283\n",
      "Epoch [420], val_loss: 7123.0229\n",
      "Epoch [440], val_loss: 7122.9214\n",
      "Epoch [460], val_loss: 7122.8330\n",
      "Epoch [480], val_loss: 7122.8062\n",
      "Epoch [500], val_loss: 7122.7305\n",
      "Epoch [520], val_loss: 7122.6943\n",
      "Epoch [540], val_loss: 7122.6411\n",
      "Epoch [550], val_loss: 7122.6396\n"
     ]
    }
   ],
   "source": [
    "epochs = 550\n",
    "lr = 1e-3\n",
    "history4 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "b2wUoPyxyxr_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7122.6318\n",
      "Epoch [40], val_loss: 7122.6250\n",
      "Epoch [60], val_loss: 7122.6138\n",
      "Epoch [80], val_loss: 7122.6108\n",
      "Epoch [100], val_loss: 7122.6021\n",
      "Epoch [120], val_loss: 7122.6025\n",
      "Epoch [140], val_loss: 7122.5967\n",
      "Epoch [160], val_loss: 7122.5884\n",
      "Epoch [180], val_loss: 7122.5791\n",
      "Epoch [200], val_loss: 7122.5728\n",
      "Epoch [220], val_loss: 7122.5659\n",
      "Epoch [240], val_loss: 7122.5610\n",
      "Epoch [260], val_loss: 7122.5547\n"
     ]
    }
   ],
   "source": [
    "epochs = 260\n",
    "lr = 1e-4\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YRirobDyxsE"
   },
   "source": [
    "**Q: What is the final validation loss of your model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "gPJmX2EEyxsE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'val_loss': 14141.197265625}, {'val_loss': 7179.92529296875}, {'val_loss': 7178.9638671875}, {'val_loss': 7177.671875}, {'val_loss': 7176.72119140625}, {'val_loss': 7175.90673828125}, {'val_loss': 7174.8447265625}, {'val_loss': 7173.44580078125}, {'val_loss': 7172.35400390625}, {'val_loss': 7171.6884765625}, {'val_loss': 7170.84912109375}, {'val_loss': 7170.28271484375}, {'val_loss': 7169.7587890625}, {'val_loss': 7168.69970703125}, {'val_loss': 7167.75048828125}, {'val_loss': 7167.20849609375}, {'val_loss': 7166.58349609375}, {'val_loss': 7165.64990234375}, {'val_loss': 7164.9443359375}, {'val_loss': 7164.2587890625}, {'val_loss': 7163.3349609375}, {'val_loss': 7162.1708984375}, {'val_loss': 7161.9072265625}, {'val_loss': 7161.1357421875}, {'val_loss': 7160.59814453125}, {'val_loss': 7159.8212890625}, {'val_loss': 7159.42431640625}, {'val_loss': 7158.65087890625}, {'val_loss': 7157.71533203125}, {'val_loss': 7157.43212890625}, {'val_loss': 7156.85107421875}, {'val_loss': 7156.6416015625}, {'val_loss': 7155.99609375}, {'val_loss': 7155.44775390625}, {'val_loss': 7155.07275390625}, {'val_loss': 7154.3505859375}, {'val_loss': 7153.4716796875}, {'val_loss': 7153.20751953125}, {'val_loss': 7152.8681640625}, {'val_loss': 7152.58837890625}, {'val_loss': 7152.05224609375}, {'val_loss': 7151.65234375}, {'val_loss': 7151.36279296875}, {'val_loss': 7151.08251953125}, {'val_loss': 7150.4970703125}, {'val_loss': 7150.13916015625}, {'val_loss': 7149.859375}, {'val_loss': 7149.49365234375}, {'val_loss': 7149.3203125}, {'val_loss': 7149.03955078125}, {'val_loss': 7148.66064453125}, {'val_loss': 7148.04638671875}, {'val_loss': 7148.09033203125}, {'val_loss': 7147.91943359375}, {'val_loss': 7148.01416015625}, {'val_loss': 7147.9375}, {'val_loss': 7147.56298828125}, {'val_loss': 7147.24365234375}, {'val_loss': 7146.95849609375}, {'val_loss': 7147.08837890625}, {'val_loss': 7147.18408203125}, {'val_loss': 7146.85595703125}, {'val_loss': 7146.73291015625}, {'val_loss': 7146.6689453125}, {'val_loss': 7146.68896484375}, {'val_loss': 7146.3525390625}, {'val_loss': 7146.30810546875}, {'val_loss': 7146.20654296875}, {'val_loss': 7146.07958984375}, {'val_loss': 7145.8046875}, {'val_loss': 7145.79345703125}, {'val_loss': 7145.58154296875}, {'val_loss': 7145.62109375}, {'val_loss': 7145.4794921875}, {'val_loss': 7145.42431640625}, {'val_loss': 7145.02880859375}, {'val_loss': 7144.73828125}, {'val_loss': 7144.48095703125}, {'val_loss': 7144.37255859375}, {'val_loss': 7144.66650390625}, {'val_loss': 7144.34912109375}, {'val_loss': 7144.12890625}, {'val_loss': 7143.68310546875}, {'val_loss': 7143.68359375}, {'val_loss': 7143.47412109375}, {'val_loss': 7143.36376953125}, {'val_loss': 7143.16162109375}, {'val_loss': 7143.08154296875}, {'val_loss': 7142.68896484375}, {'val_loss': 7142.67626953125}, {'val_loss': 7142.4521484375}, {'val_loss': 7142.3359375}, {'val_loss': 7142.63671875}, {'val_loss': 7142.69482421875}, {'val_loss': 7143.00537109375}, {'val_loss': 7143.11669921875}, {'val_loss': 7142.8984375}, {'val_loss': 7142.5791015625}, {'val_loss': 7142.73193359375}, {'val_loss': 7142.47802734375}, {'val_loss': 7142.5654296875}, {'val_loss': 7142.6689453125}, {'val_loss': 7142.5478515625}, {'val_loss': 7142.53515625}, {'val_loss': 7142.31640625}, {'val_loss': 7142.29443359375}, {'val_loss': 7142.15576171875}, {'val_loss': 7142.1943359375}, {'val_loss': 7142.09814453125}, {'val_loss': 7142.20068359375}, {'val_loss': 7142.14404296875}, {'val_loss': 7142.109375}, {'val_loss': 7141.84765625}, {'val_loss': 7142.09228515625}, {'val_loss': 7142.26611328125}, {'val_loss': 7142.38720703125}, {'val_loss': 7142.52587890625}, {'val_loss': 7142.58642578125}, {'val_loss': 7142.71533203125}, {'val_loss': 7142.9296875}, {'val_loss': 7143.13232421875}, {'val_loss': 7143.25439453125}, {'val_loss': 7143.51025390625}, {'val_loss': 7143.75830078125}, {'val_loss': 7143.6552734375}, {'val_loss': 7143.66845703125}, {'val_loss': 7143.703125}, {'val_loss': 7143.86474609375}, {'val_loss': 7143.9140625}, {'val_loss': 7143.98095703125}, {'val_loss': 7144.1982421875}, {'val_loss': 7144.17626953125}, {'val_loss': 7144.20849609375}, {'val_loss': 7144.39599609375}, {'val_loss': 7144.57080078125}, {'val_loss': 7144.6279296875}, {'val_loss': 7144.75146484375}, {'val_loss': 7145.0712890625}, {'val_loss': 7144.9736328125}, {'val_loss': 7145.0146484375}, {'val_loss': 7145.09814453125}, {'val_loss': 7145.18505859375}, {'val_loss': 7145.06396484375}, {'val_loss': 7144.87255859375}, {'val_loss': 7144.9814453125}, {'val_loss': 7144.96630859375}, {'val_loss': 7144.78955078125}, {'val_loss': 7144.75}, {'val_loss': 7144.6875}, {'val_loss': 7144.81005859375}, {'val_loss': 7145.01806640625}, {'val_loss': 7145.00439453125}, {'val_loss': 7144.72900390625}, {'val_loss': 7144.84619140625}, {'val_loss': 7144.98974609375}, {'val_loss': 7145.12744140625}, {'val_loss': 7145.16015625}, {'val_loss': 7145.33056640625}, {'val_loss': 7145.3515625}, {'val_loss': 7145.2744140625}, {'val_loss': 7145.33154296875}, {'val_loss': 7145.40478515625}, {'val_loss': 7145.65087890625}, {'val_loss': 7145.69677734375}, {'val_loss': 7145.5341796875}, {'val_loss': 7145.2802734375}, {'val_loss': 7145.140625}, {'val_loss': 7145.296875}, {'val_loss': 7145.3857421875}, {'val_loss': 7145.43603515625}, {'val_loss': 7145.57373046875}, {'val_loss': 7145.40673828125}, {'val_loss': 7145.44140625}, {'val_loss': 7145.54736328125}, {'val_loss': 7145.6650390625}, {'val_loss': 7145.81396484375}, {'val_loss': 7145.84521484375}, {'val_loss': 7145.81005859375}, {'val_loss': 7145.61962890625}, {'val_loss': 7145.77685546875}, {'val_loss': 7145.81689453125}, {'val_loss': 7145.97509765625}, {'val_loss': 7145.9814453125}, {'val_loss': 7145.91015625}, {'val_loss': 7145.95068359375}, {'val_loss': 7146.07177734375}, {'val_loss': 7146.2353515625}, {'val_loss': 7146.21044921875}, {'val_loss': 7146.19140625}, {'val_loss': 7146.19775390625}, {'val_loss': 7146.2919921875}, {'val_loss': 7146.26611328125}, {'val_loss': 7146.31005859375}, {'val_loss': 7146.27978515625}, {'val_loss': 7146.53564453125}, {'val_loss': 7146.5791015625}, {'val_loss': 7146.56640625}, {'val_loss': 7146.46044921875}, {'val_loss': 7146.4375}, {'val_loss': 7146.45751953125}, {'val_loss': 7146.30615234375}, {'val_loss': 7146.29150390625}, {'val_loss': 7146.21044921875}, {'val_loss': 7146.32861328125}, {'val_loss': 7146.53125}, {'val_loss': 7146.47216796875}, {'val_loss': 7146.4697265625}, {'val_loss': 7146.51318359375}, {'val_loss': 7146.78125}, {'val_loss': 7146.74609375}, {'val_loss': 7146.83740234375}, {'val_loss': 7146.671875}, {'val_loss': 7146.9248046875}, {'val_loss': 7147.13037109375}, {'val_loss': 7147.10888671875}, {'val_loss': 7147.1455078125}, {'val_loss': 7147.31689453125}, {'val_loss': 7147.15234375}, {'val_loss': 7147.1044921875}, {'val_loss': 7146.890625}, {'val_loss': 7146.9375}, {'val_loss': 7146.80859375}, {'val_loss': 7147.0146484375}, {'val_loss': 7146.94091796875}, {'val_loss': 7146.8447265625}, {'val_loss': 7146.81005859375}, {'val_loss': 7146.97216796875}, {'val_loss': 7146.8232421875}, {'val_loss': 7147.0009765625}, {'val_loss': 7147.00732421875}, {'val_loss': 7147.11474609375}, {'val_loss': 7147.26025390625}, {'val_loss': 7147.10693359375}, {'val_loss': 7147.05029296875}, {'val_loss': 7146.96826171875}, {'val_loss': 7147.15625}, {'val_loss': 7147.09619140625}, {'val_loss': 7147.2734375}, {'val_loss': 7147.1181640625}, {'val_loss': 7147.0390625}, {'val_loss': 7146.99609375}, {'val_loss': 7147.11474609375}, {'val_loss': 7147.12548828125}, {'val_loss': 7147.0341796875}, {'val_loss': 7147.07421875}, {'val_loss': 7147.0478515625}, {'val_loss': 7146.97265625}, {'val_loss': 7147.1064453125}, {'val_loss': 7147.19287109375}, {'val_loss': 7147.2412109375}, {'val_loss': 7147.23876953125}, {'val_loss': 7147.24853515625}, {'val_loss': 7147.25732421875}, {'val_loss': 7147.19482421875}, {'val_loss': 7147.10205078125}, {'val_loss': 7147.0791015625}, {'val_loss': 7147.1259765625}, {'val_loss': 7147.0849609375}, {'val_loss': 7147.31103515625}, {'val_loss': 7147.1474609375}, {'val_loss': 7147.07470703125}, {'val_loss': 7147.0703125}, {'val_loss': 7147.00634765625}, {'val_loss': 7147.1884765625}, {'val_loss': 7147.05078125}, {'val_loss': 7147.06689453125}, {'val_loss': 7147.01708984375}, {'val_loss': 7147.06005859375}, {'val_loss': 7147.0361328125}, {'val_loss': 7146.96484375}, {'val_loss': 7147.125}, {'val_loss': 7147.07763671875}, {'val_loss': 7146.93896484375}, {'val_loss': 7146.94580078125}, {'val_loss': 7147.0048828125}, {'val_loss': 7146.9931640625}, {'val_loss': 7147.0478515625}, {'val_loss': 7147.01318359375}, {'val_loss': 7147.0947265625}, {'val_loss': 7147.16162109375}, {'val_loss': 7147.00341796875}, {'val_loss': 7147.02685546875}, {'val_loss': 7147.06396484375}, {'val_loss': 7147.10009765625}, {'val_loss': 7147.17041015625}, {'val_loss': 7147.07080078125}, {'val_loss': 7147.0166015625}, {'val_loss': 7147.0400390625}, {'val_loss': 7147.06591796875}, {'val_loss': 7147.0166015625}, {'val_loss': 7147.0263671875}, {'val_loss': 7147.0673828125}, {'val_loss': 7146.9990234375}, {'val_loss': 7146.87890625}, {'val_loss': 7146.84814453125}, {'val_loss': 7146.82861328125}, {'val_loss': 7146.67919921875}, {'val_loss': 7146.77734375}, {'val_loss': 7146.66162109375}, {'val_loss': 7146.77685546875}, {'val_loss': 7146.8662109375}, {'val_loss': 7146.7724609375}, {'val_loss': 7146.7314453125}, {'val_loss': 7146.7421875}, {'val_loss': 7146.6064453125}, {'val_loss': 7146.7880859375}, {'val_loss': 7146.79345703125}, {'val_loss': 7146.7470703125}, {'val_loss': 7146.68701171875}, {'val_loss': 7146.68310546875}, {'val_loss': 7146.5107421875}, {'val_loss': 7146.52490234375}, {'val_loss': 7146.6220703125}, {'val_loss': 7146.67529296875}, {'val_loss': 7146.6845703125}, {'val_loss': 7146.671875}, {'val_loss': 7146.72900390625}, {'val_loss': 7146.7744140625}, {'val_loss': 7146.60986328125}, {'val_loss': 7146.5615234375}, {'val_loss': 7146.6572265625}, {'val_loss': 7146.6162109375}, {'val_loss': 7146.6220703125}, {'val_loss': 7146.69287109375}, {'val_loss': 7146.6796875}, {'val_loss': 7146.64306640625}, {'val_loss': 7146.6552734375}, {'val_loss': 7146.65087890625}, {'val_loss': 7146.56201171875}, {'val_loss': 7146.65625}, {'val_loss': 7146.68212890625}, {'val_loss': 7146.64404296875}, {'val_loss': 7146.61376953125}, {'val_loss': 7146.6337890625}, {'val_loss': 7146.50732421875}, {'val_loss': 7146.61865234375}, {'val_loss': 7146.54296875}, {'val_loss': 7146.62451171875}, {'val_loss': 7146.42626953125}, {'val_loss': 7146.35693359375}, {'val_loss': 7146.28125}, {'val_loss': 7146.2744140625}, {'val_loss': 7146.22119140625}, {'val_loss': 7146.22509765625}, {'val_loss': 7146.26220703125}, {'val_loss': 7146.234375}, {'val_loss': 7146.1572265625}, {'val_loss': 7146.15625}, {'val_loss': 7146.19970703125}, {'val_loss': 7146.2783203125}, {'val_loss': 7146.1259765625}, {'val_loss': 7146.11962890625}, {'val_loss': 7146.12255859375}, {'val_loss': 7146.08154296875}, {'val_loss': 7146.04443359375}, {'val_loss': 7145.87158203125}, {'val_loss': 7145.86376953125}, {'val_loss': 7145.8818359375}, {'val_loss': 7145.84521484375}, {'val_loss': 7145.77685546875}, {'val_loss': 7145.7197265625}, {'val_loss': 7145.7275390625}, {'val_loss': 7145.76025390625}, {'val_loss': 7145.69189453125}, {'val_loss': 7145.5908203125}, {'val_loss': 7145.61962890625}, {'val_loss': 7145.74072265625}, {'val_loss': 7145.73291015625}, {'val_loss': 7145.6845703125}, {'val_loss': 7145.80517578125}, {'val_loss': 7145.80419921875}, {'val_loss': 7145.91357421875}, {'val_loss': 7145.79931640625}, {'val_loss': 7145.59814453125}, {'val_loss': 7145.56298828125}, {'val_loss': 7145.47607421875}, {'val_loss': 7145.3857421875}, {'val_loss': 7145.27978515625}, {'val_loss': 7145.32861328125}, {'val_loss': 7145.22412109375}, {'val_loss': 7145.21484375}, {'val_loss': 7145.05712890625}, {'val_loss': 7145.11328125}, {'val_loss': 7145.25}, {'val_loss': 7145.3310546875}, {'val_loss': 7145.26318359375}, {'val_loss': 7145.1796875}, {'val_loss': 7145.21435546875}, {'val_loss': 7145.0966796875}, {'val_loss': 7145.0771484375}, {'val_loss': 7145.15869140625}, {'val_loss': 7145.11181640625}, {'val_loss': 7145.0234375}, {'val_loss': 7144.95654296875}, {'val_loss': 7144.89306640625}, {'val_loss': 7145.078125}, {'val_loss': 7145.25}, {'val_loss': 7145.06103515625}, {'val_loss': 7144.9150390625}, {'val_loss': 7144.80810546875}, {'val_loss': 7144.91943359375}, {'val_loss': 7144.87646484375}, {'val_loss': 7144.82080078125}, {'val_loss': 7144.8359375}, {'val_loss': 7144.65869140625}, {'val_loss': 7144.64697265625}, {'val_loss': 7144.74658203125}, {'val_loss': 7144.7177734375}, {'val_loss': 7144.5791015625}, {'val_loss': 7144.578125}, {'val_loss': 7144.60546875}, {'val_loss': 7144.4677734375}, {'val_loss': 7144.3310546875}, {'val_loss': 7144.34033203125}, {'val_loss': 7144.24267578125}, {'val_loss': 7144.22607421875}, {'val_loss': 7144.13720703125}, {'val_loss': 7144.12451171875}, {'val_loss': 7144.15966796875}, {'val_loss': 7144.08251953125}, {'val_loss': 7144.15625}, {'val_loss': 7143.9501953125}, {'val_loss': 7143.9560546875}, {'val_loss': 7144.00439453125}, {'val_loss': 7143.84765625}, {'val_loss': 7143.93017578125}, {'val_loss': 7143.86669921875}, {'val_loss': 7143.8115234375}, {'val_loss': 7143.72216796875}, {'val_loss': 7143.59033203125}, {'val_loss': 7143.62890625}, {'val_loss': 7143.76904296875}, {'val_loss': 7143.75634765625}, {'val_loss': 7143.6826171875}, {'val_loss': 7143.5947265625}, {'val_loss': 7143.67822265625}, {'val_loss': 7143.6962890625}, {'val_loss': 7143.6259765625}, {'val_loss': 7143.6435546875}, {'val_loss': 7143.60693359375}, {'val_loss': 7143.4638671875}, {'val_loss': 7143.3974609375}, {'val_loss': 7143.42822265625}, {'val_loss': 7143.27294921875}, {'val_loss': 7143.2841796875}, {'val_loss': 7143.15966796875}, {'val_loss': 7143.19482421875}, {'val_loss': 7143.18408203125}, {'val_loss': 7143.09130859375}, {'val_loss': 7142.90771484375}, {'val_loss': 7142.93701171875}, {'val_loss': 7143.01220703125}, {'val_loss': 7142.96826171875}, {'val_loss': 7142.8740234375}, {'val_loss': 7142.99609375}, {'val_loss': 7143.06298828125}, {'val_loss': 7142.91748046875}, {'val_loss': 7142.8662109375}, {'val_loss': 7142.8369140625}, {'val_loss': 7142.7265625}, {'val_loss': 7142.8330078125}, {'val_loss': 7142.84033203125}, {'val_loss': 7142.64453125}, {'val_loss': 7142.61279296875}, {'val_loss': 7142.69482421875}, {'val_loss': 7142.67041015625}, {'val_loss': 7142.69384765625}, {'val_loss': 7142.54150390625}, {'val_loss': 7142.41845703125}, {'val_loss': 7142.42724609375}, {'val_loss': 7142.3935546875}, {'val_loss': 7142.20849609375}, {'val_loss': 7142.1806640625}, {'val_loss': 7142.23046875}, {'val_loss': 7142.2421875}, {'val_loss': 7142.2392578125}, {'val_loss': 7142.40576171875}, {'val_loss': 7142.19189453125}, {'val_loss': 7142.01123046875}, {'val_loss': 7141.9306640625}, {'val_loss': 7141.9306640625}, {'val_loss': 7142.04638671875}, {'val_loss': 7141.9306640625}, {'val_loss': 7141.78076171875}, {'val_loss': 7141.82275390625}, {'val_loss': 7141.88525390625}, {'val_loss': 7141.96533203125}, {'val_loss': 7141.875}, {'val_loss': 7141.84619140625}, {'val_loss': 7141.88232421875}, {'val_loss': 7141.875}, {'val_loss': 7141.60546875}, {'val_loss': 7141.3916015625}, {'val_loss': 7141.43994140625}, {'val_loss': 7141.4677734375}, {'val_loss': 7141.35693359375}, {'val_loss': 7141.36669921875}, {'val_loss': 7141.29248046875}, {'val_loss': 7141.3134765625}, {'val_loss': 7141.28662109375}, {'val_loss': 7141.20068359375}, {'val_loss': 7141.25927734375}, {'val_loss': 7141.25830078125}, {'val_loss': 7141.26220703125}, {'val_loss': 7141.28759765625}, {'val_loss': 7141.05859375}, {'val_loss': 7141.02734375}, {'val_loss': 7141.0478515625}, {'val_loss': 7141.19091796875}, {'val_loss': 7141.11376953125}, {'val_loss': 7141.109375}, {'val_loss': 7141.03173828125}, {'val_loss': 7140.9150390625}, {'val_loss': 7140.83984375}, {'val_loss': 7140.63037109375}, {'val_loss': 7140.6728515625}, {'val_loss': 7140.4638671875}, {'val_loss': 7140.42626953125}, {'val_loss': 7140.56005859375}, {'val_loss': 7140.60302734375}, {'val_loss': 7140.46533203125}, {'val_loss': 7140.51123046875}, {'val_loss': 7140.6064453125}, {'val_loss': 7140.5205078125}, {'val_loss': 7140.39453125}, {'val_loss': 7140.5400390625}, {'val_loss': 7140.46435546875}, {'val_loss': 7140.32666015625}, {'val_loss': 7140.31591796875}, {'val_loss': 7140.25634765625}, {'val_loss': 7140.21533203125}, {'val_loss': 7140.2607421875}, {'val_loss': 7140.1884765625}, {'val_loss': 7140.33154296875}, {'val_loss': 7140.1904296875}, {'val_loss': 7140.21826171875}, {'val_loss': 7139.96484375}, {'val_loss': 7139.97998046875}, {'val_loss': 7139.68896484375}, {'val_loss': 7139.6298828125}, {'val_loss': 7139.57275390625}, {'val_loss': 7139.50048828125}, {'val_loss': 7139.42919921875}, {'val_loss': 7139.43115234375}, {'val_loss': 7139.5}, {'val_loss': 7139.42626953125}, {'val_loss': 7139.38232421875}, {'val_loss': 7139.31982421875}, {'val_loss': 7139.3271484375}, {'val_loss': 7139.4638671875}, {'val_loss': 7139.39404296875}, {'val_loss': 7139.4052734375}, {'val_loss': 7139.30712890625}, {'val_loss': 7139.2578125}, {'val_loss': 7139.3515625}, {'val_loss': 7139.48681640625}, {'val_loss': 7139.56884765625}, {'val_loss': 7139.33056640625}, {'val_loss': 7139.37841796875}, {'val_loss': 7139.37158203125}, {'val_loss': 7139.43896484375}, {'val_loss': 7139.31689453125}, {'val_loss': 7139.16162109375}, {'val_loss': 7139.0712890625}, {'val_loss': 7139.05419921875}, {'val_loss': 7138.95751953125}, {'val_loss': 7139.1201171875}, {'val_loss': 7139.1572265625}, {'val_loss': 7138.94482421875}, {'val_loss': 7138.78369140625}, {'val_loss': 7138.9296875}, {'val_loss': 7138.63623046875}, {'val_loss': 7138.65576171875}, {'val_loss': 7138.5419921875}, {'val_loss': 7138.58740234375}, {'val_loss': 7138.52783203125}, {'val_loss': 7138.58447265625}, {'val_loss': 7138.82666015625}, {'val_loss': 7138.6796875}, {'val_loss': 7138.53271484375}, {'val_loss': 7138.57470703125}, {'val_loss': 7138.41943359375}, {'val_loss': 7138.52880859375}, {'val_loss': 7138.30126953125}, {'val_loss': 7138.1982421875}, {'val_loss': 7138.1591796875}, {'val_loss': 7138.18701171875}, {'val_loss': 7138.0283203125}, {'val_loss': 7137.93603515625}, {'val_loss': 7137.97802734375}, {'val_loss': 7137.97314453125}, {'val_loss': 7137.96826171875}, {'val_loss': 7138.00048828125}, {'val_loss': 7138.14306640625}, {'val_loss': 7137.953125}, {'val_loss': 7138.0986328125}, {'val_loss': 7137.82568359375}, {'val_loss': 7137.83447265625}, {'val_loss': 7137.86962890625}, {'val_loss': 7137.5771484375}, {'val_loss': 7137.52587890625}, {'val_loss': 7137.6005859375}, {'val_loss': 7137.47265625}, {'val_loss': 7137.1708984375}, {'val_loss': 7137.1923828125}, {'val_loss': 7137.1767578125}, {'val_loss': 7137.421875}, {'val_loss': 7137.46533203125}, {'val_loss': 7137.32568359375}, {'val_loss': 7137.2421875}, {'val_loss': 7137.36328125}, {'val_loss': 7137.26318359375}, {'val_loss': 7137.2626953125}, {'val_loss': 7137.19921875}, {'val_loss': 7137.09716796875}, {'val_loss': 7137.2021484375}, {'val_loss': 7136.8818359375}, {'val_loss': 7136.9541015625}, {'val_loss': 7136.73974609375}, {'val_loss': 7136.7314453125}, {'val_loss': 7136.70751953125}, {'val_loss': 7136.72900390625}, {'val_loss': 7136.85107421875}, {'val_loss': 7136.83642578125}, {'val_loss': 7136.64501953125}, {'val_loss': 7136.7333984375}, {'val_loss': 7136.73974609375}, {'val_loss': 7136.68359375}, {'val_loss': 7136.640625}, {'val_loss': 7136.78369140625}, {'val_loss': 7136.67236328125}, {'val_loss': 7136.62744140625}, {'val_loss': 7136.5947265625}, {'val_loss': 7136.3212890625}, {'val_loss': 7136.2958984375}, {'val_loss': 7136.18017578125}, {'val_loss': 7136.26318359375}, {'val_loss': 7136.31640625}, {'val_loss': 7136.4833984375}, {'val_loss': 7136.40185546875}, {'val_loss': 7136.37548828125}, {'val_loss': 7135.94677734375}, {'val_loss': 7135.7509765625}, {'val_loss': 7135.69873046875}, {'val_loss': 7135.87890625}, {'val_loss': 7135.94873046875}, {'val_loss': 7135.94384765625}, {'val_loss': 7135.84814453125}, {'val_loss': 7135.55419921875}, {'val_loss': 7135.61962890625}, {'val_loss': 7135.84130859375}, {'val_loss': 7135.7822265625}, {'val_loss': 7135.90185546875}, {'val_loss': 7135.859375}, {'val_loss': 7135.77783203125}, {'val_loss': 7135.56494140625}, {'val_loss': 7135.60888671875}, {'val_loss': 7135.72119140625}, {'val_loss': 7135.65966796875}, {'val_loss': 7135.44970703125}, {'val_loss': 7135.48974609375}, {'val_loss': 7135.39599609375}, {'val_loss': 7135.56982421875}, {'val_loss': 7135.5029296875}, {'val_loss': 7135.47412109375}, {'val_loss': 7135.44189453125}, {'val_loss': 7135.45068359375}, {'val_loss': 7135.15869140625}, {'val_loss': 7135.26708984375}, {'val_loss': 7135.04931640625}, {'val_loss': 7134.96630859375}, {'val_loss': 7135.05078125}, {'val_loss': 7134.93505859375}, {'val_loss': 7134.76611328125}, {'val_loss': 7134.6953125}, {'val_loss': 7134.8671875}, {'val_loss': 7134.8544921875}, {'val_loss': 7134.86083984375}, {'val_loss': 7134.7568359375}, {'val_loss': 7134.70849609375}, {'val_loss': 7134.6943359375}, {'val_loss': 7134.7373046875}, {'val_loss': 7134.7802734375}, {'val_loss': 7134.51953125}, {'val_loss': 7134.5615234375}, {'val_loss': 7134.38134765625}, {'val_loss': 7134.38330078125}, {'val_loss': 7134.35986328125}, {'val_loss': 7134.39990234375}, {'val_loss': 7134.35498046875}, {'val_loss': 7134.4892578125}, {'val_loss': 7134.3837890625}, {'val_loss': 7134.23388671875}, {'val_loss': 7134.25244140625}, {'val_loss': 7133.859375}, {'val_loss': 7133.84375}, {'val_loss': 7133.81298828125}, {'val_loss': 7133.84716796875}, {'val_loss': 7133.89306640625}, {'val_loss': 7133.89111328125}, {'val_loss': 7133.6884765625}, {'val_loss': 7133.7412109375}, {'val_loss': 7133.70751953125}, {'val_loss': 7133.70263671875}, {'val_loss': 7133.74462890625}, {'val_loss': 7133.61279296875}, {'val_loss': 7133.3779296875}, {'val_loss': 7133.32470703125}, {'val_loss': 7133.32568359375}, {'val_loss': 7133.453125}, {'val_loss': 7133.22021484375}, {'val_loss': 7133.3115234375}, {'val_loss': 7133.13525390625}, {'val_loss': 7133.21728515625}, {'val_loss': 7133.0869140625}, {'val_loss': 7133.09375}, {'val_loss': 7133.1865234375}, {'val_loss': 7133.27099609375}, {'val_loss': 7133.2294921875}, {'val_loss': 7133.36181640625}, {'val_loss': 7133.26513671875}, {'val_loss': 7133.07568359375}, {'val_loss': 7133.05029296875}, {'val_loss': 7133.17626953125}, {'val_loss': 7133.25634765625}, {'val_loss': 7133.0263671875}, {'val_loss': 7133.1376953125}, {'val_loss': 7133.05712890625}, {'val_loss': 7132.94775390625}, {'val_loss': 7133.015625}, {'val_loss': 7132.88720703125}, {'val_loss': 7132.73974609375}, {'val_loss': 7132.80322265625}, {'val_loss': 7132.6845703125}, {'val_loss': 7132.5927734375}, {'val_loss': 7132.60498046875}, {'val_loss': 7132.47412109375}, {'val_loss': 7132.47607421875}, {'val_loss': 7132.4619140625}, {'val_loss': 7132.6181640625}, {'val_loss': 7132.55322265625}, {'val_loss': 7132.2021484375}, {'val_loss': 7132.25439453125}, {'val_loss': 7132.06884765625}, {'val_loss': 7131.97216796875}, {'val_loss': 7132.0751953125}, {'val_loss': 7132.2138671875}, {'val_loss': 7132.2421875}, {'val_loss': 7132.22265625}, {'val_loss': 7132.1357421875}, {'val_loss': 7132.1181640625}, {'val_loss': 7131.9326171875}, {'val_loss': 7132.02392578125}, {'val_loss': 7132.03759765625}, {'val_loss': 7131.82763671875}, {'val_loss': 7131.75}, {'val_loss': 7131.64111328125}, {'val_loss': 7131.6396484375}, {'val_loss': 7131.53515625}, {'val_loss': 7131.5791015625}, {'val_loss': 7131.6875}, {'val_loss': 7131.6689453125}, {'val_loss': 7131.703125}, {'val_loss': 7131.60302734375}, {'val_loss': 7131.64404296875}, {'val_loss': 7131.37744140625}, {'val_loss': 7131.38525390625}, {'val_loss': 7131.1259765625}, {'val_loss': 7131.3466796875}, {'val_loss': 7131.5341796875}, {'val_loss': 7131.2890625}, {'val_loss': 7131.14892578125}, {'val_loss': 7131.0537109375}, {'val_loss': 7131.16748046875}, {'val_loss': 7130.9921875}, {'val_loss': 7131.1064453125}, {'val_loss': 7131.28955078125}, {'val_loss': 7131.0673828125}, {'val_loss': 7131.29541015625}, {'val_loss': 7131.20166015625}, {'val_loss': 7131.17529296875}, {'val_loss': 7131.1806640625}, {'val_loss': 7131.19287109375}, {'val_loss': 7130.81689453125}, {'val_loss': 7130.66357421875}, {'val_loss': 7130.75}, {'val_loss': 7130.7470703125}, {'val_loss': 7130.72607421875}, {'val_loss': 7130.61279296875}, {'val_loss': 7130.4443359375}, {'val_loss': 7130.3447265625}, {'val_loss': 7130.4345703125}, {'val_loss': 7130.3271484375}, {'val_loss': 7130.41455078125}, {'val_loss': 7130.2802734375}, {'val_loss': 7130.1357421875}, {'val_loss': 7130.2490234375}, {'val_loss': 7130.26806640625}, {'val_loss': 7130.1298828125}, {'val_loss': 7130.03076171875}, {'val_loss': 7130.2265625}, {'val_loss': 7130.09814453125}, {'val_loss': 7130.35205078125}, {'val_loss': 7130.3505859375}, {'val_loss': 7130.1953125}, {'val_loss': 7130.140625}, {'val_loss': 7130.1064453125}, {'val_loss': 7129.91748046875}, {'val_loss': 7129.88525390625}, {'val_loss': 7129.8359375}, {'val_loss': 7129.7177734375}, {'val_loss': 7129.7177734375}, {'val_loss': 7129.68798828125}, {'val_loss': 7129.63720703125}, {'val_loss': 7129.63134765625}, {'val_loss': 7129.5615234375}, {'val_loss': 7129.60009765625}, {'val_loss': 7129.7119140625}, {'val_loss': 7129.4951171875}, {'val_loss': 7129.609375}, {'val_loss': 7129.4833984375}, {'val_loss': 7129.50439453125}, {'val_loss': 7129.30419921875}, {'val_loss': 7129.40283203125}, {'val_loss': 7129.27001953125}, {'val_loss': 7129.23193359375}, {'val_loss': 7129.4287109375}, {'val_loss': 7129.40625}, {'val_loss': 7129.2255859375}, {'val_loss': 7129.31103515625}, {'val_loss': 7129.12646484375}, {'val_loss': 7129.18798828125}, {'val_loss': 7129.22216796875}, {'val_loss': 7129.01806640625}, {'val_loss': 7129.10107421875}, {'val_loss': 7128.89599609375}, {'val_loss': 7128.89794921875}, {'val_loss': 7128.86865234375}, {'val_loss': 7128.9140625}, {'val_loss': 7128.8740234375}, {'val_loss': 7128.7421875}, {'val_loss': 7128.66748046875}, {'val_loss': 7128.87255859375}, {'val_loss': 7128.7880859375}, {'val_loss': 7128.6943359375}, {'val_loss': 7128.6376953125}, {'val_loss': 7128.90478515625}, {'val_loss': 7128.96240234375}, {'val_loss': 7129.03857421875}, {'val_loss': 7129.14599609375}, {'val_loss': 7128.8193359375}, {'val_loss': 7128.5595703125}, {'val_loss': 7128.55029296875}, {'val_loss': 7128.52587890625}, {'val_loss': 7128.58837890625}, {'val_loss': 7128.57275390625}, {'val_loss': 7128.64453125}, {'val_loss': 7128.47998046875}, {'val_loss': 7128.48681640625}, {'val_loss': 7128.4521484375}, {'val_loss': 7128.5361328125}, {'val_loss': 7128.4599609375}, {'val_loss': 7128.45751953125}, {'val_loss': 7128.46533203125}, {'val_loss': 7128.38427734375}, {'val_loss': 7128.2587890625}, {'val_loss': 7128.21630859375}, {'val_loss': 7128.06005859375}, {'val_loss': 7128.05517578125}, {'val_loss': 7127.87744140625}, {'val_loss': 7127.83349609375}, {'val_loss': 7127.8046875}, {'val_loss': 7127.92041015625}, {'val_loss': 7128.16357421875}, {'val_loss': 7128.00439453125}, {'val_loss': 7127.7890625}, {'val_loss': 7127.59765625}, {'val_loss': 7127.66455078125}, {'val_loss': 7127.5693359375}, {'val_loss': 7127.39501953125}, {'val_loss': 7127.34765625}, {'val_loss': 7127.35791015625}, {'val_loss': 7127.30029296875}, {'val_loss': 7127.45556640625}, {'val_loss': 7127.51953125}, {'val_loss': 7127.5576171875}, {'val_loss': 7127.23583984375}, {'val_loss': 7127.3447265625}, {'val_loss': 7127.3662109375}, {'val_loss': 7127.42333984375}, {'val_loss': 7127.35791015625}, {'val_loss': 7127.34716796875}, {'val_loss': 7127.3740234375}, {'val_loss': 7127.4140625}, {'val_loss': 7127.41943359375}, {'val_loss': 7127.4658203125}, {'val_loss': 7127.31298828125}, {'val_loss': 7127.1259765625}, {'val_loss': 7127.15673828125}, {'val_loss': 7127.33154296875}, {'val_loss': 7127.03369140625}, {'val_loss': 7127.23193359375}, {'val_loss': 7127.60986328125}, {'val_loss': 7127.33447265625}, {'val_loss': 7127.18798828125}, {'val_loss': 7127.1611328125}, {'val_loss': 7126.89306640625}, {'val_loss': 7126.85888671875}, {'val_loss': 7127.00048828125}, {'val_loss': 7126.91064453125}, {'val_loss': 7126.72412109375}, {'val_loss': 7126.7890625}, {'val_loss': 7127.05126953125}, {'val_loss': 7127.06982421875}, {'val_loss': 7126.77001953125}, {'val_loss': 7126.5400390625}, {'val_loss': 7126.65283203125}, {'val_loss': 7126.84912109375}, {'val_loss': 7126.6337890625}, {'val_loss': 7126.4931640625}, {'val_loss': 7126.5322265625}, {'val_loss': 7126.3388671875}, {'val_loss': 7126.52978515625}, {'val_loss': 7126.4404296875}, {'val_loss': 7126.42724609375}, {'val_loss': 7126.36767578125}, {'val_loss': 7126.41162109375}, {'val_loss': 7126.64599609375}, {'val_loss': 7126.59130859375}, {'val_loss': 7126.35498046875}, {'val_loss': 7126.30322265625}, {'val_loss': 7126.28662109375}, {'val_loss': 7126.40478515625}, {'val_loss': 7126.18310546875}, {'val_loss': 7126.13232421875}, {'val_loss': 7126.1552734375}, {'val_loss': 7126.4375}, {'val_loss': 7126.78271484375}, {'val_loss': 7126.45166015625}, {'val_loss': 7126.1748046875}, {'val_loss': 7126.27392578125}, {'val_loss': 7126.01025390625}, {'val_loss': 7125.72119140625}, {'val_loss': 7125.60107421875}, {'val_loss': 7125.74755859375}, {'val_loss': 7125.89013671875}, {'val_loss': 7125.93310546875}, {'val_loss': 7125.9990234375}, {'val_loss': 7126.13720703125}, {'val_loss': 7126.2587890625}, {'val_loss': 7126.3017578125}, {'val_loss': 7125.9052734375}, {'val_loss': 7125.86767578125}, {'val_loss': 7125.7119140625}, {'val_loss': 7125.45263671875}, {'val_loss': 7125.6005859375}, {'val_loss': 7125.63134765625}, {'val_loss': 7125.45751953125}, {'val_loss': 7125.69189453125}, {'val_loss': 7125.9599609375}, {'val_loss': 7125.68310546875}, {'val_loss': 7125.4482421875}, {'val_loss': 7125.30615234375}, {'val_loss': 7125.36474609375}, {'val_loss': 7125.50537109375}, {'val_loss': 7125.6337890625}, {'val_loss': 7125.78564453125}, {'val_loss': 7125.68994140625}, {'val_loss': 7125.48974609375}, {'val_loss': 7125.42333984375}, {'val_loss': 7125.34228515625}, {'val_loss': 7125.19384765625}, {'val_loss': 7125.27294921875}, {'val_loss': 7125.0771484375}, {'val_loss': 7124.9287109375}, {'val_loss': 7125.10888671875}, {'val_loss': 7125.3046875}, {'val_loss': 7125.41064453125}, {'val_loss': 7125.22119140625}, {'val_loss': 7124.87451171875}, {'val_loss': 7124.83203125}, {'val_loss': 7124.6748046875}, {'val_loss': 7124.74560546875}, {'val_loss': 7124.48291015625}, {'val_loss': 7124.5078125}, {'val_loss': 7124.65185546875}, {'val_loss': 7124.6484375}, {'val_loss': 7124.70703125}, {'val_loss': 7124.62646484375}, {'val_loss': 7124.5615234375}, {'val_loss': 7124.63720703125}, {'val_loss': 7124.61328125}, {'val_loss': 7124.6240234375}, {'val_loss': 7124.34375}, {'val_loss': 7124.3359375}, {'val_loss': 7124.125}, {'val_loss': 7124.28125}, {'val_loss': 7124.23876953125}, {'val_loss': 7124.20556640625}, {'val_loss': 7124.38916015625}, {'val_loss': 7124.28955078125}, {'val_loss': 7124.2900390625}, {'val_loss': 7124.28857421875}, {'val_loss': 7124.2880859375}, {'val_loss': 7124.2880859375}, {'val_loss': 7124.28857421875}, {'val_loss': 7124.28662109375}, {'val_loss': 7124.28662109375}, {'val_loss': 7124.28564453125}, {'val_loss': 7124.28564453125}, {'val_loss': 7124.28466796875}, {'val_loss': 7124.28466796875}, {'val_loss': 7124.2841796875}, {'val_loss': 7124.28271484375}, {'val_loss': 7124.2822265625}, {'val_loss': 7124.2822265625}, {'val_loss': 7124.28173828125}, {'val_loss': 7124.28173828125}, {'val_loss': 7124.28173828125}, {'val_loss': 7124.2822265625}, {'val_loss': 7124.28173828125}, {'val_loss': 7124.2822265625}, {'val_loss': 7124.28173828125}, {'val_loss': 7124.28173828125}, {'val_loss': 7124.2822265625}, {'val_loss': 7124.2822265625}, {'val_loss': 7124.28173828125}, {'val_loss': 7124.28076171875}, {'val_loss': 7124.27978515625}, {'val_loss': 7124.27978515625}, {'val_loss': 7124.27880859375}, {'val_loss': 7124.2763671875}, {'val_loss': 7124.2763671875}, {'val_loss': 7124.2763671875}, {'val_loss': 7124.27490234375}, {'val_loss': 7124.2763671875}, {'val_loss': 7124.27587890625}, {'val_loss': 7124.27587890625}, {'val_loss': 7124.27587890625}, {'val_loss': 7124.27490234375}, {'val_loss': 7124.27490234375}, {'val_loss': 7124.27587890625}, {'val_loss': 7124.27490234375}, {'val_loss': 7124.27587890625}, {'val_loss': 7124.2744140625}, {'val_loss': 7124.2734375}, {'val_loss': 7124.2724609375}, {'val_loss': 7124.27099609375}, {'val_loss': 7124.2705078125}, {'val_loss': 7124.26904296875}, {'val_loss': 7124.26904296875}, {'val_loss': 7124.2685546875}, {'val_loss': 7124.26904296875}, {'val_loss': 7124.26806640625}, {'val_loss': 7124.26806640625}, {'val_loss': 7124.26904296875}, {'val_loss': 7124.26904296875}, {'val_loss': 7124.26806640625}, {'val_loss': 7124.26904296875}, {'val_loss': 7124.26904296875}, {'val_loss': 7124.26806640625}, {'val_loss': 7124.2666015625}, {'val_loss': 7124.26708984375}, {'val_loss': 7124.265625}, {'val_loss': 7124.265625}, {'val_loss': 7124.26513671875}, {'val_loss': 7124.265625}, {'val_loss': 7124.265625}, {'val_loss': 7124.2646484375}, {'val_loss': 7124.26611328125}, {'val_loss': 7124.26611328125}, {'val_loss': 7124.2666015625}, {'val_loss': 7124.26708984375}, {'val_loss': 7124.265625}, {'val_loss': 7124.26611328125}, {'val_loss': 7124.2646484375}, {'val_loss': 7124.26513671875}, {'val_loss': 7124.26513671875}, {'val_loss': 7124.2666015625}, {'val_loss': 7124.265625}, {'val_loss': 7124.26611328125}, {'val_loss': 7124.265625}, {'val_loss': 7124.265625}, {'val_loss': 7124.265625}, {'val_loss': 7124.26513671875}, {'val_loss': 7124.26416015625}, {'val_loss': 7124.26318359375}, {'val_loss': 7124.26318359375}, {'val_loss': 7124.2626953125}, {'val_loss': 7124.2626953125}, {'val_loss': 7124.2626953125}, {'val_loss': 7124.26318359375}, {'val_loss': 7124.26171875}, {'val_loss': 7124.2626953125}, {'val_loss': 7124.2626953125}, {'val_loss': 7124.26220703125}, {'val_loss': 7124.26220703125}, {'val_loss': 7124.26220703125}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26171875}, {'val_loss': 7124.26171875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26025390625}, {'val_loss': 7124.26025390625}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26171875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.2607421875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26123046875}, {'val_loss': 7124.26171875}, {'val_loss': 7124.26171875}, {'val_loss': 7124.2607421875}, {'val_loss': 7124.26025390625}, {'val_loss': 7124.25830078125}, {'val_loss': 7124.25732421875}, {'val_loss': 7124.25537109375}, {'val_loss': 7124.25439453125}, {'val_loss': 7124.25390625}, {'val_loss': 7124.25341796875}, {'val_loss': 7124.2529296875}, {'val_loss': 7124.2509765625}, {'val_loss': 7124.2529296875}, {'val_loss': 7124.2529296875}, {'val_loss': 7124.25146484375}, {'val_loss': 7124.2509765625}, {'val_loss': 7124.24951171875}, {'val_loss': 7124.2490234375}, {'val_loss': 7124.2490234375}, {'val_loss': 7124.24755859375}, {'val_loss': 7124.24755859375}, {'val_loss': 7124.24755859375}, {'val_loss': 7124.24609375}, {'val_loss': 7124.24755859375}, {'val_loss': 7124.24658203125}, {'val_loss': 7124.24658203125}, {'val_loss': 7124.24658203125}, {'val_loss': 7124.24560546875}, {'val_loss': 7124.24609375}, {'val_loss': 7124.24609375}, {'val_loss': 7124.24658203125}, {'val_loss': 7124.2451171875}, {'val_loss': 7124.24365234375}, {'val_loss': 7124.2421875}, {'val_loss': 7124.2412109375}, {'val_loss': 7124.2421875}, {'val_loss': 7124.2431640625}, {'val_loss': 7124.2431640625}, {'val_loss': 7124.2421875}, {'val_loss': 7124.24169921875}, {'val_loss': 7124.2412109375}, {'val_loss': 7124.23974609375}, {'val_loss': 7124.2392578125}, {'val_loss': 7124.23876953125}, {'val_loss': 7124.23876953125}, {'val_loss': 7124.23828125}, {'val_loss': 7124.23779296875}, {'val_loss': 7124.2373046875}, {'val_loss': 7124.23681640625}, {'val_loss': 7124.23681640625}, {'val_loss': 7124.2353515625}, {'val_loss': 7124.23486328125}, {'val_loss': 7124.23486328125}, {'val_loss': 7124.23486328125}, {'val_loss': 7124.2353515625}, {'val_loss': 7124.23681640625}, {'val_loss': 7124.23779296875}, {'val_loss': 7124.23779296875}, {'val_loss': 7124.2373046875}, {'val_loss': 7124.2373046875}, {'val_loss': 7124.23681640625}, {'val_loss': 7124.23583984375}, {'val_loss': 7124.23681640625}, {'val_loss': 7124.23681640625}, {'val_loss': 7124.23486328125}, {'val_loss': 7124.234375}, {'val_loss': 7124.2353515625}, {'val_loss': 7124.2353515625}, {'val_loss': 7124.23486328125}, {'val_loss': 7124.23486328125}, {'val_loss': 7124.2353515625}, {'val_loss': 7124.23486328125}, {'val_loss': 7124.234375}, {'val_loss': 7124.23388671875}, {'val_loss': 7124.23193359375}, {'val_loss': 7124.23193359375}, {'val_loss': 7124.23193359375}, {'val_loss': 7124.2333984375}, {'val_loss': 7124.23095703125}, {'val_loss': 7124.2314453125}, {'val_loss': 7124.23095703125}, {'val_loss': 7124.2314453125}, {'val_loss': 7124.23095703125}, {'val_loss': 7124.23046875}, {'val_loss': 7124.23095703125}, {'val_loss': 7124.22998046875}, {'val_loss': 7124.22998046875}, {'val_loss': 7124.22998046875}, {'val_loss': 7124.2294921875}, {'val_loss': 7124.22900390625}, {'val_loss': 7124.2275390625}, {'val_loss': 7124.2275390625}, {'val_loss': 7124.22705078125}, {'val_loss': 7124.2275390625}, {'val_loss': 7124.2275390625}, {'val_loss': 7124.22705078125}, {'val_loss': 7124.2265625}, {'val_loss': 7124.22607421875}, {'val_loss': 7124.2265625}, {'val_loss': 7124.22607421875}, {'val_loss': 7124.2265625}, {'val_loss': 7124.22607421875}, {'val_loss': 7124.22509765625}, {'val_loss': 7124.22509765625}, {'val_loss': 7124.22412109375}, {'val_loss': 7124.22509765625}, {'val_loss': 7124.2236328125}, {'val_loss': 7124.22412109375}, {'val_loss': 7124.22314453125}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.2236328125}, {'val_loss': 7124.22265625}, {'val_loss': 7124.22265625}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.22265625}, {'val_loss': 7124.22314453125}, {'val_loss': 7124.22314453125}, {'val_loss': 7124.22314453125}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.2216796875}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.22265625}, {'val_loss': 7124.22314453125}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.2216796875}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.2216796875}, {'val_loss': 7124.22216796875}, {'val_loss': 7124.22119140625}, {'val_loss': 7124.22119140625}, {'val_loss': 7124.2197265625}, {'val_loss': 7124.2197265625}, {'val_loss': 7124.22021484375}, {'val_loss': 7124.2197265625}, {'val_loss': 7124.2197265625}, {'val_loss': 7124.2197265625}, {'val_loss': 7124.22021484375}, {'val_loss': 7124.22021484375}, {'val_loss': 7124.2197265625}, {'val_loss': 7124.21923828125}, {'val_loss': 7124.21875}, {'val_loss': 7124.2197265625}, {'val_loss': 7124.21923828125}, {'val_loss': 7124.21826171875}, {'val_loss': 7124.21728515625}, {'val_loss': 7124.21630859375}, {'val_loss': 7124.21728515625}, {'val_loss': 7124.21875}, {'val_loss': 7124.21630859375}, {'val_loss': 7124.21533203125}, {'val_loss': 7124.2158203125}, {'val_loss': 7124.21484375}, {'val_loss': 7124.21435546875}, {'val_loss': 7124.21337890625}, {'val_loss': 7124.2119140625}, {'val_loss': 7124.21240234375}, {'val_loss': 7124.2119140625}, {'val_loss': 7124.2109375}, {'val_loss': 7124.2109375}, {'val_loss': 7124.21044921875}, {'val_loss': 7124.2109375}, {'val_loss': 7124.2109375}, {'val_loss': 7124.20947265625}, {'val_loss': 7124.20947265625}, {'val_loss': 7124.20849609375}, {'val_loss': 7124.20849609375}, {'val_loss': 7124.2080078125}, {'val_loss': 7124.2080078125}, {'val_loss': 7124.2080078125}, {'val_loss': 7124.20654296875}, {'val_loss': 7124.20654296875}, {'val_loss': 7124.20556640625}, {'val_loss': 7124.20654296875}, {'val_loss': 7124.20458984375}, {'val_loss': 7124.2041015625}, {'val_loss': 7124.2041015625}, {'val_loss': 7124.20361328125}, {'val_loss': 7124.20361328125}, {'val_loss': 7124.203125}, {'val_loss': 7124.203125}, {'val_loss': 7124.20263671875}, {'val_loss': 7124.2021484375}, {'val_loss': 7124.2021484375}, {'val_loss': 7124.2021484375}, {'val_loss': 7124.2001953125}, {'val_loss': 7124.19921875}, {'val_loss': 7124.19921875}, {'val_loss': 7124.1982421875}, {'val_loss': 7124.19775390625}, {'val_loss': 7124.1982421875}, {'val_loss': 7124.19677734375}, {'val_loss': 7124.19775390625}, {'val_loss': 7124.1962890625}, {'val_loss': 7124.19677734375}, {'val_loss': 7124.1953125}, {'val_loss': 7124.1943359375}, {'val_loss': 7124.19287109375}, {'val_loss': 7124.19384765625}, {'val_loss': 7124.19384765625}, {'val_loss': 7124.1943359375}, {'val_loss': 7124.1953125}, {'val_loss': 7124.19677734375}, {'val_loss': 7124.1962890625}, {'val_loss': 7124.1953125}, {'val_loss': 7124.1953125}, {'val_loss': 7124.1953125}, {'val_loss': 7124.19482421875}, {'val_loss': 7124.1943359375}, {'val_loss': 7124.19384765625}, {'val_loss': 7124.19384765625}, {'val_loss': 7124.1923828125}, {'val_loss': 7124.19384765625}, {'val_loss': 7124.1923828125}, {'val_loss': 7124.19287109375}, {'val_loss': 7124.19189453125}, {'val_loss': 7124.19189453125}, {'val_loss': 7124.19189453125}, {'val_loss': 7124.19091796875}, {'val_loss': 7124.18994140625}, {'val_loss': 7124.18994140625}, {'val_loss': 7124.1904296875}, {'val_loss': 7124.1904296875}, {'val_loss': 7124.18896484375}, {'val_loss': 7124.1884765625}, {'val_loss': 7124.1884765625}, {'val_loss': 7124.18896484375}, {'val_loss': 7124.18896484375}, {'val_loss': 7124.18994140625}, {'val_loss': 7124.1904296875}, {'val_loss': 7124.18994140625}, {'val_loss': 7124.18994140625}, {'val_loss': 7124.18798828125}, {'val_loss': 7124.18603515625}, {'val_loss': 7124.1865234375}, {'val_loss': 7124.1865234375}, {'val_loss': 7124.1865234375}, {'val_loss': 7124.18603515625}, {'val_loss': 7124.18603515625}, {'val_loss': 7124.1865234375}, {'val_loss': 7124.18701171875}, {'val_loss': 7124.18505859375}, {'val_loss': 7124.18603515625}, {'val_loss': 7124.18603515625}, {'val_loss': 7124.18505859375}, {'val_loss': 7124.18359375}, {'val_loss': 7124.18359375}, {'val_loss': 7124.18310546875}, {'val_loss': 7124.18408203125}, {'val_loss': 7124.18115234375}, {'val_loss': 7124.18115234375}, {'val_loss': 7124.18115234375}, {'val_loss': 7124.1806640625}, {'val_loss': 7124.18017578125}, {'val_loss': 7124.18017578125}, {'val_loss': 7124.1787109375}, {'val_loss': 7124.17724609375}, {'val_loss': 7124.17724609375}, {'val_loss': 7124.17724609375}, {'val_loss': 7124.1767578125}, {'val_loss': 7124.1787109375}, {'val_loss': 7124.1767578125}, {'val_loss': 7124.1767578125}, {'val_loss': 7124.1767578125}, {'val_loss': 7124.17578125}, {'val_loss': 7124.17626953125}, {'val_loss': 7124.17578125}, {'val_loss': 7124.17529296875}, {'val_loss': 7124.17431640625}, {'val_loss': 7124.17333984375}, {'val_loss': 7124.1748046875}, {'val_loss': 7124.17529296875}, {'val_loss': 7124.1748046875}, {'val_loss': 7124.17529296875}, {'val_loss': 7124.17431640625}, {'val_loss': 7124.17333984375}, {'val_loss': 7124.17333984375}, {'val_loss': 7124.17236328125}, {'val_loss': 7124.17236328125}, {'val_loss': 7124.17138671875}, {'val_loss': 7124.171875}, {'val_loss': 7124.17236328125}, {'val_loss': 7124.171875}, {'val_loss': 7124.171875}, {'val_loss': 7124.17138671875}, {'val_loss': 7124.16943359375}, {'val_loss': 7124.17041015625}, {'val_loss': 7124.1689453125}, {'val_loss': 7124.16943359375}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16796875}, {'val_loss': 7124.16943359375}, {'val_loss': 7124.17041015625}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.1689453125}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16943359375}, {'val_loss': 7124.16943359375}, {'val_loss': 7124.17041015625}, {'val_loss': 7124.1708984375}, {'val_loss': 7124.17138671875}, {'val_loss': 7124.1708984375}, {'val_loss': 7124.17041015625}, {'val_loss': 7124.17236328125}, {'val_loss': 7124.17138671875}, {'val_loss': 7124.17138671875}, {'val_loss': 7124.1708984375}, {'val_loss': 7124.17236328125}, {'val_loss': 7124.17236328125}, {'val_loss': 7124.171875}, {'val_loss': 7124.17138671875}, {'val_loss': 7124.17041015625}, {'val_loss': 7124.16943359375}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16796875}, {'val_loss': 7124.16943359375}, {'val_loss': 7124.16796875}, {'val_loss': 7124.1689453125}, {'val_loss': 7124.16796875}, {'val_loss': 7124.16796875}, {'val_loss': 7124.1669921875}, {'val_loss': 7124.1669921875}, {'val_loss': 7124.16650390625}, {'val_loss': 7124.16650390625}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.1689453125}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16796875}, {'val_loss': 7124.1669921875}, {'val_loss': 7124.16650390625}, {'val_loss': 7124.1669921875}, {'val_loss': 7124.1669921875}, {'val_loss': 7124.16748046875}, {'val_loss': 7124.16845703125}, {'val_loss': 7124.16748046875}, {'val_loss': 7124.1669921875}, {'val_loss': 7124.16650390625}, {'val_loss': 7124.16552734375}, {'val_loss': 7124.16650390625}, {'val_loss': 7124.16650390625}, {'val_loss': 7124.16650390625}, {'val_loss': 7124.1650390625}, {'val_loss': 7124.16357421875}, {'val_loss': 7124.1630859375}, {'val_loss': 7124.1630859375}, {'val_loss': 7124.16259765625}, {'val_loss': 7124.1611328125}, {'val_loss': 7124.15966796875}, {'val_loss': 7124.15966796875}, {'val_loss': 7124.15869140625}, {'val_loss': 7124.15673828125}, {'val_loss': 7124.15625}, {'val_loss': 7124.15576171875}, {'val_loss': 7124.1552734375}, {'val_loss': 7124.15380859375}, {'val_loss': 7124.1533203125}, {'val_loss': 7124.15478515625}, {'val_loss': 7124.15380859375}, {'val_loss': 7124.15380859375}, {'val_loss': 7124.15380859375}, {'val_loss': 7124.1533203125}, {'val_loss': 7124.1533203125}, {'val_loss': 7124.15283203125}, {'val_loss': 7124.15283203125}, {'val_loss': 7124.15234375}, {'val_loss': 7124.15185546875}, {'val_loss': 7124.15185546875}, {'val_loss': 7124.15185546875}, {'val_loss': 7124.15283203125}, {'val_loss': 7124.15234375}, {'val_loss': 7124.15380859375}, {'val_loss': 7124.15380859375}, {'val_loss': 7124.1533203125}, {'val_loss': 7124.15478515625}, {'val_loss': 7124.15478515625}, {'val_loss': 7124.1533203125}, {'val_loss': 7124.1533203125}, {'val_loss': 7124.15283203125}, {'val_loss': 7124.15234375}, {'val_loss': 7124.15185546875}, {'val_loss': 7124.15185546875}, {'val_loss': 7124.15234375}, {'val_loss': 7124.15234375}, {'val_loss': 7124.15087890625}, {'val_loss': 7124.15087890625}, {'val_loss': 7124.14990234375}, {'val_loss': 7124.14892578125}, {'val_loss': 7124.14892578125}, {'val_loss': 7124.14794921875}, {'val_loss': 7124.1484375}, {'val_loss': 7124.1474609375}, {'val_loss': 7124.14892578125}, {'val_loss': 7124.14892578125}, {'val_loss': 7124.1484375}, {'val_loss': 7124.1474609375}, {'val_loss': 7124.1474609375}, {'val_loss': 7124.1484375}, {'val_loss': 7124.1484375}, {'val_loss': 7124.1474609375}, {'val_loss': 7124.1474609375}, {'val_loss': 7124.1474609375}, {'val_loss': 7124.1455078125}, {'val_loss': 7124.14501953125}, {'val_loss': 7124.1455078125}, {'val_loss': 7124.14501953125}, {'val_loss': 7124.14453125}, {'val_loss': 7124.1435546875}, {'val_loss': 7124.1435546875}, {'val_loss': 7124.1435546875}, {'val_loss': 7124.1416015625}, {'val_loss': 7124.14111328125}, {'val_loss': 7124.1396484375}, {'val_loss': 7124.14013671875}, {'val_loss': 7124.13916015625}, {'val_loss': 7124.13818359375}, {'val_loss': 7124.13623046875}, {'val_loss': 7124.13623046875}, {'val_loss': 7124.1357421875}, {'val_loss': 7124.13671875}, {'val_loss': 7124.13671875}, {'val_loss': 7124.13671875}, {'val_loss': 7124.13720703125}, {'val_loss': 7124.13623046875}, {'val_loss': 7124.1357421875}, {'val_loss': 7124.13623046875}, {'val_loss': 7124.1357421875}, {'val_loss': 7124.13525390625}, {'val_loss': 7124.13427734375}, {'val_loss': 7124.13330078125}, {'val_loss': 7124.1328125}, {'val_loss': 7124.1328125}, {'val_loss': 7124.1318359375}, {'val_loss': 7124.1318359375}, {'val_loss': 7124.13232421875}, {'val_loss': 7124.13232421875}, {'val_loss': 7124.13232421875}, {'val_loss': 7124.13232421875}, {'val_loss': 7124.13232421875}, {'val_loss': 7124.1318359375}, {'val_loss': 7124.13134765625}, {'val_loss': 7124.13134765625}, {'val_loss': 7124.12939453125}, {'val_loss': 7124.12890625}, {'val_loss': 7124.12890625}, {'val_loss': 7124.1279296875}, {'val_loss': 7124.1279296875}, {'val_loss': 7124.12744140625}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.1259765625}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12744140625}, {'val_loss': 7124.1279296875}, {'val_loss': 7124.12890625}, {'val_loss': 7124.12939453125}, {'val_loss': 7124.12890625}, {'val_loss': 7124.1279296875}, {'val_loss': 7124.12841796875}, {'val_loss': 7124.12841796875}, {'val_loss': 7124.12841796875}, {'val_loss': 7124.12841796875}, {'val_loss': 7124.1279296875}, {'val_loss': 7124.12744140625}, {'val_loss': 7124.12744140625}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.1259765625}, {'val_loss': 7124.12744140625}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12744140625}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.1259765625}, {'val_loss': 7124.12548828125}, {'val_loss': 7124.12646484375}, {'val_loss': 7124.1259765625}, {'val_loss': 7124.1259765625}, {'val_loss': 7124.12548828125}, {'val_loss': 7124.125}, {'val_loss': 7124.12548828125}, {'val_loss': 7124.12255859375}, {'val_loss': 7124.12255859375}, {'val_loss': 7124.12109375}, {'val_loss': 7124.12109375}, {'val_loss': 7124.12060546875}, {'val_loss': 7124.12060546875}, {'val_loss': 7124.11962890625}, {'val_loss': 7124.12158203125}, {'val_loss': 7124.12060546875}, {'val_loss': 7124.1201171875}, {'val_loss': 7124.11865234375}, {'val_loss': 7124.1181640625}, {'val_loss': 7124.11767578125}, {'val_loss': 7124.1162109375}, {'val_loss': 7124.1162109375}, {'val_loss': 7124.1162109375}, {'val_loss': 7124.11376953125}, {'val_loss': 7124.11328125}, {'val_loss': 7124.1142578125}, {'val_loss': 7124.11279296875}, {'val_loss': 7124.11279296875}, {'val_loss': 7124.11279296875}, {'val_loss': 7124.11181640625}, {'val_loss': 7124.11083984375}, {'val_loss': 7124.11181640625}, {'val_loss': 7124.11181640625}, {'val_loss': 7124.11083984375}, {'val_loss': 7124.11083984375}, {'val_loss': 7124.11181640625}, {'val_loss': 7124.10986328125}, {'val_loss': 7124.10986328125}, {'val_loss': 7124.10888671875}, {'val_loss': 7124.1083984375}, {'val_loss': 7124.1083984375}, {'val_loss': 7124.10595703125}, {'val_loss': 7124.10595703125}, {'val_loss': 7124.10595703125}, {'val_loss': 7124.1064453125}, {'val_loss': 7124.10595703125}, {'val_loss': 7124.10498046875}, {'val_loss': 7124.10546875}, {'val_loss': 7124.1044921875}, {'val_loss': 7124.10400390625}, {'val_loss': 7124.1025390625}, {'val_loss': 7124.1025390625}, {'val_loss': 7124.10107421875}, {'val_loss': 7124.1015625}, {'val_loss': 7124.10107421875}, {'val_loss': 7124.10009765625}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.09716796875}, {'val_loss': 7124.09716796875}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.09814453125}, {'val_loss': 7124.09814453125}, {'val_loss': 7124.0966796875}, {'val_loss': 7124.09619140625}, {'val_loss': 7124.09716796875}, {'val_loss': 7124.09716796875}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.09912109375}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.10009765625}, {'val_loss': 7124.09814453125}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.09912109375}, {'val_loss': 7124.09912109375}, {'val_loss': 7124.09912109375}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.09814453125}, {'val_loss': 7124.0986328125}, {'val_loss': 7124.09765625}, {'val_loss': 7124.09619140625}, {'val_loss': 7124.09521484375}, {'val_loss': 7124.09619140625}, {'val_loss': 7124.09521484375}, {'val_loss': 7124.09521484375}, {'val_loss': 7124.0947265625}, {'val_loss': 7124.09423828125}, {'val_loss': 7124.0947265625}, {'val_loss': 7124.09326171875}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.09375}, {'val_loss': 7124.09375}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.09228515625}, {'val_loss': 7124.09423828125}, {'val_loss': 7124.09375}, {'val_loss': 7124.09375}, {'val_loss': 7124.09326171875}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.09130859375}, {'val_loss': 7124.09228515625}, {'val_loss': 7124.09228515625}, {'val_loss': 7124.09033203125}, {'val_loss': 7124.09130859375}, {'val_loss': 7124.09033203125}, {'val_loss': 7124.0908203125}, {'val_loss': 7124.0908203125}, {'val_loss': 7124.0908203125}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.09228515625}, {'val_loss': 7124.09228515625}, {'val_loss': 7124.09375}, {'val_loss': 7124.09375}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.0908203125}, {'val_loss': 7124.0927734375}, {'val_loss': 7124.0908203125}, {'val_loss': 7124.09033203125}, {'val_loss': 7124.0888671875}, {'val_loss': 7124.08935546875}, {'val_loss': 7124.0888671875}, {'val_loss': 7124.0869140625}, {'val_loss': 7124.08642578125}, {'val_loss': 7124.08642578125}, {'val_loss': 7124.08544921875}, {'val_loss': 7124.08642578125}, {'val_loss': 7124.0849609375}, {'val_loss': 7124.08544921875}, {'val_loss': 7124.08447265625}, {'val_loss': 7124.0849609375}, {'val_loss': 7124.0849609375}, {'val_loss': 7124.08447265625}, {'val_loss': 7124.08349609375}, {'val_loss': 7124.08349609375}, {'val_loss': 7124.08349609375}, {'val_loss': 7124.0830078125}, {'val_loss': 7124.08447265625}, {'val_loss': 7124.08447265625}, {'val_loss': 7124.08251953125}, {'val_loss': 7124.08203125}, {'val_loss': 7124.08056640625}, {'val_loss': 7124.0791015625}, {'val_loss': 7124.08056640625}, {'val_loss': 7124.08056640625}, {'val_loss': 7124.07958984375}, {'val_loss': 7124.07958984375}, {'val_loss': 7124.0791015625}, {'val_loss': 7124.078125}, {'val_loss': 7124.0771484375}, {'val_loss': 7124.07470703125}, {'val_loss': 7124.0751953125}, {'val_loss': 7124.07568359375}, {'val_loss': 7124.07568359375}, {'val_loss': 7124.07470703125}, {'val_loss': 7124.0751953125}, {'val_loss': 7124.07568359375}, {'val_loss': 7124.07568359375}, {'val_loss': 7124.07568359375}, {'val_loss': 7124.07470703125}, {'val_loss': 7124.07470703125}, {'val_loss': 7124.07373046875}, {'val_loss': 7124.0732421875}, {'val_loss': 7124.0732421875}, {'val_loss': 7124.07373046875}, {'val_loss': 7124.0732421875}, {'val_loss': 7124.07275390625}, {'val_loss': 7124.07177734375}, {'val_loss': 7124.0703125}, {'val_loss': 7124.07080078125}, {'val_loss': 7124.0693359375}, {'val_loss': 7124.06982421875}, {'val_loss': 7124.06787109375}, {'val_loss': 7124.06787109375}, {'val_loss': 7124.06787109375}, {'val_loss': 7124.0673828125}, {'val_loss': 7124.06787109375}, {'val_loss': 7124.06884765625}, {'val_loss': 7124.06884765625}, {'val_loss': 7124.06884765625}, {'val_loss': 7124.06787109375}, {'val_loss': 7124.0693359375}, {'val_loss': 7124.06884765625}, {'val_loss': 7124.06787109375}, {'val_loss': 7124.06689453125}, {'val_loss': 7124.06787109375}, {'val_loss': 7124.06689453125}, {'val_loss': 7124.06689453125}, {'val_loss': 7124.06689453125}, {'val_loss': 7124.0654296875}, {'val_loss': 7124.06494140625}, {'val_loss': 7124.06494140625}, {'val_loss': 7124.06494140625}, {'val_loss': 7124.0654296875}, {'val_loss': 7124.06591796875}, {'val_loss': 7124.0654296875}, {'val_loss': 7124.0654296875}, {'val_loss': 7124.0654296875}, {'val_loss': 7124.0634765625}, {'val_loss': 7124.0625}, {'val_loss': 7124.0625}, {'val_loss': 7124.06298828125}, {'val_loss': 7124.0625}, {'val_loss': 7124.06201171875}, {'val_loss': 7124.0634765625}, {'val_loss': 7124.06201171875}, {'val_loss': 7124.0625}, {'val_loss': 7124.0625}, {'val_loss': 7124.0615234375}, {'val_loss': 7124.06201171875}, {'val_loss': 7124.06201171875}, {'val_loss': 7124.0615234375}, {'val_loss': 7124.0615234375}, {'val_loss': 7124.06103515625}, {'val_loss': 7124.05859375}, {'val_loss': 7124.05908203125}, {'val_loss': 7124.05810546875}, {'val_loss': 7124.05712890625}, {'val_loss': 7124.05712890625}, {'val_loss': 7124.05712890625}, {'val_loss': 7124.05810546875}, {'val_loss': 7124.05712890625}, {'val_loss': 7124.0556640625}, {'val_loss': 7124.0556640625}, {'val_loss': 7124.05615234375}, {'val_loss': 7124.05712890625}, {'val_loss': 7124.05712890625}, {'val_loss': 7124.0576171875}, {'val_loss': 7124.05712890625}, {'val_loss': 7124.05517578125}, {'val_loss': 7124.05517578125}, {'val_loss': 7124.0546875}, {'val_loss': 7124.0537109375}, {'val_loss': 7124.05224609375}, {'val_loss': 7124.0537109375}, {'val_loss': 7124.0537109375}, {'val_loss': 7124.05419921875}, {'val_loss': 7124.05419921875}, {'val_loss': 7124.0537109375}, {'val_loss': 7124.0537109375}, {'val_loss': 7124.05322265625}, {'val_loss': 7124.05322265625}, {'val_loss': 7124.0517578125}, {'val_loss': 7124.0517578125}, {'val_loss': 7124.05126953125}, {'val_loss': 7124.05126953125}, {'val_loss': 7124.0498046875}, {'val_loss': 7124.05029296875}, {'val_loss': 7124.05078125}, {'val_loss': 7124.05029296875}, {'val_loss': 7124.0498046875}, {'val_loss': 7124.046875}, {'val_loss': 7124.0458984375}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.0458984375}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.04345703125}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.04296875}, {'val_loss': 7124.04296875}, {'val_loss': 7124.04296875}, {'val_loss': 7124.04248046875}, {'val_loss': 7124.04248046875}, {'val_loss': 7124.04248046875}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.0458984375}, {'val_loss': 7124.0458984375}, {'val_loss': 7124.0458984375}, {'val_loss': 7124.04541015625}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.04443359375}, {'val_loss': 7124.0439453125}, {'val_loss': 7124.04345703125}, {'val_loss': 7124.04150390625}, {'val_loss': 7124.04150390625}, {'val_loss': 7124.04150390625}, {'val_loss': 7124.04052734375}, {'val_loss': 7124.0400390625}, {'val_loss': 7124.03955078125}, {'val_loss': 7124.04052734375}, {'val_loss': 7124.03955078125}, {'val_loss': 7124.0390625}, {'val_loss': 7124.03759765625}, {'val_loss': 7124.03662109375}, {'val_loss': 7124.03662109375}, {'val_loss': 7124.03515625}, {'val_loss': 7124.0361328125}, {'val_loss': 7124.03515625}, {'val_loss': 7124.03515625}, {'val_loss': 7124.03515625}, {'val_loss': 7124.03564453125}, {'val_loss': 7124.0341796875}, {'val_loss': 7124.03369140625}, {'val_loss': 7124.03369140625}, {'val_loss': 7124.0322265625}, {'val_loss': 7124.0322265625}, {'val_loss': 7124.0322265625}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.03173828125}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.03125}, {'val_loss': 7124.0302734375}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.02880859375}, {'val_loss': 7124.0302734375}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.03173828125}, {'val_loss': 7124.03125}, {'val_loss': 7124.03173828125}, {'val_loss': 7124.0302734375}, {'val_loss': 7124.0302734375}, {'val_loss': 7124.03125}, {'val_loss': 7124.0283203125}, {'val_loss': 7124.02880859375}, {'val_loss': 7124.02978515625}, {'val_loss': 7124.02978515625}, {'val_loss': 7124.02880859375}, {'val_loss': 7124.02880859375}, {'val_loss': 7124.03076171875}, {'val_loss': 7124.0302734375}, {'val_loss': 7124.0302734375}, {'val_loss': 7124.02880859375}, {'val_loss': 7124.0283203125}, {'val_loss': 7124.02734375}, {'val_loss': 7124.0263671875}, {'val_loss': 7124.02587890625}, {'val_loss': 7124.0263671875}, {'val_loss': 7124.02587890625}, {'val_loss': 7124.02734375}, {'val_loss': 7124.02685546875}, {'val_loss': 7124.02685546875}, {'val_loss': 7124.0263671875}, {'val_loss': 7124.0263671875}, {'val_loss': 7124.0263671875}, {'val_loss': 7124.02587890625}, {'val_loss': 7124.0263671875}, {'val_loss': 7124.02490234375}, {'val_loss': 7124.0244140625}, {'val_loss': 7124.02294921875}, {'val_loss': 7124.0234375}, {'val_loss': 7124.02294921875}, {'val_loss': 7124.0244140625}, {'val_loss': 7124.02294921875}, {'val_loss': 7124.02294921875}, {'val_loss': 7124.0224609375}, {'val_loss': 7124.0224609375}, {'val_loss': 7124.0224609375}, {'val_loss': 7124.02099609375}, {'val_loss': 7124.0224609375}, {'val_loss': 7124.02099609375}, {'val_loss': 7124.02197265625}, {'val_loss': 7124.0224609375}, {'val_loss': 7124.02294921875}, {'val_loss': 7124.02294921875}, {'val_loss': 7124.0234375}, {'val_loss': 7124.0244140625}, {'val_loss': 7124.0244140625}, {'val_loss': 7124.02392578125}, {'val_loss': 7124.0234375}, {'val_loss': 7124.0224609375}, {'val_loss': 7124.02197265625}, {'val_loss': 7124.02197265625}, {'val_loss': 7124.02197265625}, {'val_loss': 7124.02197265625}, {'val_loss': 7124.02197265625}, {'val_loss': 7124.0205078125}, {'val_loss': 7124.02001953125}, {'val_loss': 7124.02099609375}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.02001953125}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01953125}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01806640625}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.0185546875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01953125}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.01904296875}, {'val_loss': 7124.0166015625}, {'val_loss': 7124.0205078125}, {'val_loss': 7124.02197265625}, {'val_loss': 7124.02685546875}, {'val_loss': 7124.02294921875}, {'val_loss': 7124.01220703125}, {'val_loss': 7124.0029296875}, {'val_loss': 7123.99267578125}, {'val_loss': 7124.00537109375}, {'val_loss': 7123.9970703125}, {'val_loss': 7123.99169921875}, {'val_loss': 7123.98779296875}, {'val_loss': 7123.9833984375}, {'val_loss': 7123.9892578125}, {'val_loss': 7123.98681640625}, {'val_loss': 7123.9814453125}, {'val_loss': 7123.9794921875}, {'val_loss': 7123.98291015625}, {'val_loss': 7123.99267578125}, {'val_loss': 7123.99462890625}, {'val_loss': 7123.97265625}, {'val_loss': 7123.96142578125}, {'val_loss': 7123.96044921875}, {'val_loss': 7123.96044921875}, {'val_loss': 7123.9462890625}, {'val_loss': 7123.9453125}, {'val_loss': 7123.9306640625}, {'val_loss': 7123.9365234375}, {'val_loss': 7123.93359375}, {'val_loss': 7123.9384765625}, {'val_loss': 7123.9345703125}, {'val_loss': 7123.91552734375}, {'val_loss': 7123.9130859375}, {'val_loss': 7123.91748046875}, {'val_loss': 7123.93505859375}, {'val_loss': 7123.92333984375}, {'val_loss': 7123.92236328125}, {'val_loss': 7123.93017578125}, {'val_loss': 7123.9267578125}, {'val_loss': 7123.921875}, {'val_loss': 7123.90771484375}, {'val_loss': 7123.9072265625}, {'val_loss': 7123.90576171875}, {'val_loss': 7123.8876953125}, {'val_loss': 7123.8974609375}, {'val_loss': 7123.89697265625}, {'val_loss': 7123.87744140625}, {'val_loss': 7123.8740234375}, {'val_loss': 7123.86083984375}, {'val_loss': 7123.87158203125}, {'val_loss': 7123.86865234375}, {'val_loss': 7123.85888671875}, {'val_loss': 7123.8671875}, {'val_loss': 7123.8642578125}, {'val_loss': 7123.86474609375}, {'val_loss': 7123.84716796875}, {'val_loss': 7123.84912109375}, {'val_loss': 7123.85205078125}, {'val_loss': 7123.84912109375}, {'val_loss': 7123.85107421875}, {'val_loss': 7123.8623046875}, {'val_loss': 7123.83935546875}, {'val_loss': 7123.82470703125}, {'val_loss': 7123.8193359375}, {'val_loss': 7123.82861328125}, {'val_loss': 7123.8271484375}, {'val_loss': 7123.80078125}, {'val_loss': 7123.80615234375}, {'val_loss': 7123.80712890625}, {'val_loss': 7123.81787109375}, {'val_loss': 7123.8037109375}, {'val_loss': 7123.80224609375}, {'val_loss': 7123.80419921875}, {'val_loss': 7123.80078125}, {'val_loss': 7123.81689453125}, {'val_loss': 7123.8193359375}, {'val_loss': 7123.82275390625}, {'val_loss': 7123.8310546875}, {'val_loss': 7123.82275390625}, {'val_loss': 7123.8046875}, {'val_loss': 7123.796875}, {'val_loss': 7123.7890625}, {'val_loss': 7123.78564453125}, {'val_loss': 7123.7841796875}, {'val_loss': 7123.78466796875}, {'val_loss': 7123.78369140625}, {'val_loss': 7123.7734375}, {'val_loss': 7123.77392578125}, {'val_loss': 7123.7685546875}, {'val_loss': 7123.78466796875}, {'val_loss': 7123.76806640625}, {'val_loss': 7123.77392578125}, {'val_loss': 7123.7646484375}, {'val_loss': 7123.74853515625}, {'val_loss': 7123.7529296875}, {'val_loss': 7123.75}, {'val_loss': 7123.74755859375}, {'val_loss': 7123.74267578125}, {'val_loss': 7123.73681640625}, {'val_loss': 7123.7392578125}, {'val_loss': 7123.7265625}, {'val_loss': 7123.73828125}, {'val_loss': 7123.7265625}, {'val_loss': 7123.71484375}, {'val_loss': 7123.7119140625}, {'val_loss': 7123.72216796875}, {'val_loss': 7123.72607421875}, {'val_loss': 7123.7197265625}, {'val_loss': 7123.71923828125}, {'val_loss': 7123.71337890625}, {'val_loss': 7123.7236328125}, {'val_loss': 7123.71533203125}, {'val_loss': 7123.72607421875}, {'val_loss': 7123.72900390625}, {'val_loss': 7123.73828125}, {'val_loss': 7123.7333984375}, {'val_loss': 7123.7509765625}, {'val_loss': 7123.73486328125}, {'val_loss': 7123.72412109375}, {'val_loss': 7123.7373046875}, {'val_loss': 7123.74169921875}, {'val_loss': 7123.73681640625}, {'val_loss': 7123.7265625}, {'val_loss': 7123.7041015625}, {'val_loss': 7123.6806640625}, {'val_loss': 7123.6708984375}, {'val_loss': 7123.6748046875}, {'val_loss': 7123.67431640625}, {'val_loss': 7123.6796875}, {'val_loss': 7123.66455078125}, {'val_loss': 7123.6689453125}, {'val_loss': 7123.66162109375}, {'val_loss': 7123.65380859375}, {'val_loss': 7123.67431640625}, {'val_loss': 7123.6904296875}, {'val_loss': 7123.6669921875}, {'val_loss': 7123.66259765625}, {'val_loss': 7123.6572265625}, {'val_loss': 7123.64697265625}, {'val_loss': 7123.64990234375}, {'val_loss': 7123.64111328125}, {'val_loss': 7123.64697265625}, {'val_loss': 7123.6279296875}, {'val_loss': 7123.62841796875}, {'val_loss': 7123.63232421875}, {'val_loss': 7123.63525390625}, {'val_loss': 7123.6318359375}, {'val_loss': 7123.63525390625}, {'val_loss': 7123.6357421875}, {'val_loss': 7123.63134765625}, {'val_loss': 7123.6240234375}, {'val_loss': 7123.62548828125}, {'val_loss': 7123.63330078125}, {'val_loss': 7123.6396484375}, {'val_loss': 7123.6416015625}, {'val_loss': 7123.63623046875}, {'val_loss': 7123.62744140625}, {'val_loss': 7123.61767578125}, {'val_loss': 7123.6123046875}, {'val_loss': 7123.60986328125}, {'val_loss': 7123.59765625}, {'val_loss': 7123.6103515625}, {'val_loss': 7123.60498046875}, {'val_loss': 7123.6103515625}, {'val_loss': 7123.59619140625}, {'val_loss': 7123.58642578125}, {'val_loss': 7123.56982421875}, {'val_loss': 7123.58154296875}, {'val_loss': 7123.5625}, {'val_loss': 7123.55517578125}, {'val_loss': 7123.54833984375}, {'val_loss': 7123.5595703125}, {'val_loss': 7123.55029296875}, {'val_loss': 7123.55810546875}, {'val_loss': 7123.5595703125}, {'val_loss': 7123.57470703125}, {'val_loss': 7123.57568359375}, {'val_loss': 7123.56982421875}, {'val_loss': 7123.5625}, {'val_loss': 7123.57568359375}, {'val_loss': 7123.56884765625}, {'val_loss': 7123.56787109375}, {'val_loss': 7123.55224609375}, {'val_loss': 7123.5458984375}, {'val_loss': 7123.54150390625}, {'val_loss': 7123.53076171875}, {'val_loss': 7123.5087890625}, {'val_loss': 7123.51708984375}, {'val_loss': 7123.51416015625}, {'val_loss': 7123.51416015625}, {'val_loss': 7123.52587890625}, {'val_loss': 7123.51953125}, {'val_loss': 7123.52880859375}, {'val_loss': 7123.53173828125}, {'val_loss': 7123.5302734375}, {'val_loss': 7123.5146484375}, {'val_loss': 7123.51953125}, {'val_loss': 7123.49560546875}, {'val_loss': 7123.49609375}, {'val_loss': 7123.49560546875}, {'val_loss': 7123.50048828125}, {'val_loss': 7123.49609375}, {'val_loss': 7123.4921875}, {'val_loss': 7123.49755859375}, {'val_loss': 7123.5009765625}, {'val_loss': 7123.48828125}, {'val_loss': 7123.48974609375}, {'val_loss': 7123.4931640625}, {'val_loss': 7123.48388671875}, {'val_loss': 7123.49658203125}, {'val_loss': 7123.4912109375}, {'val_loss': 7123.51123046875}, {'val_loss': 7123.52490234375}, {'val_loss': 7123.50830078125}, {'val_loss': 7123.5107421875}, {'val_loss': 7123.50927734375}, {'val_loss': 7123.48828125}, {'val_loss': 7123.4794921875}, {'val_loss': 7123.47119140625}, {'val_loss': 7123.4560546875}, {'val_loss': 7123.45166015625}, {'val_loss': 7123.45068359375}, {'val_loss': 7123.44287109375}, {'val_loss': 7123.421875}, {'val_loss': 7123.44091796875}, {'val_loss': 7123.44091796875}, {'val_loss': 7123.44873046875}, {'val_loss': 7123.44580078125}, {'val_loss': 7123.4453125}, {'val_loss': 7123.45654296875}, {'val_loss': 7123.47900390625}, {'val_loss': 7123.4677734375}, {'val_loss': 7123.45361328125}, {'val_loss': 7123.44580078125}, {'val_loss': 7123.4462890625}, {'val_loss': 7123.4443359375}, {'val_loss': 7123.4521484375}, {'val_loss': 7123.453125}, {'val_loss': 7123.4404296875}, {'val_loss': 7123.45068359375}, {'val_loss': 7123.4404296875}, {'val_loss': 7123.41748046875}, {'val_loss': 7123.42626953125}, {'val_loss': 7123.40087890625}, {'val_loss': 7123.39013671875}, {'val_loss': 7123.41015625}, {'val_loss': 7123.3896484375}, {'val_loss': 7123.37841796875}, {'val_loss': 7123.36767578125}, {'val_loss': 7123.35302734375}, {'val_loss': 7123.35400390625}, {'val_loss': 7123.36767578125}, {'val_loss': 7123.36865234375}, {'val_loss': 7123.38671875}, {'val_loss': 7123.37939453125}, {'val_loss': 7123.36083984375}, {'val_loss': 7123.36181640625}, {'val_loss': 7123.34423828125}, {'val_loss': 7123.34814453125}, {'val_loss': 7123.3544921875}, {'val_loss': 7123.34716796875}, {'val_loss': 7123.34619140625}, {'val_loss': 7123.3369140625}, {'val_loss': 7123.32568359375}, {'val_loss': 7123.31201171875}, {'val_loss': 7123.31201171875}, {'val_loss': 7123.3115234375}, {'val_loss': 7123.32763671875}, {'val_loss': 7123.3427734375}, {'val_loss': 7123.3505859375}, {'val_loss': 7123.35302734375}, {'val_loss': 7123.34814453125}, {'val_loss': 7123.32373046875}, {'val_loss': 7123.31005859375}, {'val_loss': 7123.31298828125}, {'val_loss': 7123.3134765625}, {'val_loss': 7123.32373046875}, {'val_loss': 7123.31884765625}, {'val_loss': 7123.33251953125}, {'val_loss': 7123.33447265625}, {'val_loss': 7123.32373046875}, {'val_loss': 7123.3037109375}, {'val_loss': 7123.3076171875}, {'val_loss': 7123.30615234375}, {'val_loss': 7123.3076171875}, {'val_loss': 7123.296875}, {'val_loss': 7123.2822265625}, {'val_loss': 7123.3046875}, {'val_loss': 7123.31005859375}, {'val_loss': 7123.2939453125}, {'val_loss': 7123.2666015625}, {'val_loss': 7123.25634765625}, {'val_loss': 7123.25048828125}, {'val_loss': 7123.24609375}, {'val_loss': 7123.24658203125}, {'val_loss': 7123.2568359375}, {'val_loss': 7123.26025390625}, {'val_loss': 7123.24267578125}, {'val_loss': 7123.26318359375}, {'val_loss': 7123.26611328125}, {'val_loss': 7123.2568359375}, {'val_loss': 7123.23828125}, {'val_loss': 7123.25537109375}, {'val_loss': 7123.26025390625}, {'val_loss': 7123.24560546875}, {'val_loss': 7123.23486328125}, {'val_loss': 7123.24755859375}, {'val_loss': 7123.24365234375}, {'val_loss': 7123.2451171875}, {'val_loss': 7123.23583984375}, {'val_loss': 7123.2314453125}, {'val_loss': 7123.21728515625}, {'val_loss': 7123.25}, {'val_loss': 7123.26025390625}, {'val_loss': 7123.26220703125}, {'val_loss': 7123.2470703125}, {'val_loss': 7123.234375}, {'val_loss': 7123.22705078125}, {'val_loss': 7123.21728515625}, {'val_loss': 7123.22314453125}, {'val_loss': 7123.24169921875}, {'val_loss': 7123.23779296875}, {'val_loss': 7123.21044921875}, {'val_loss': 7123.20947265625}, {'val_loss': 7123.19677734375}, {'val_loss': 7123.2080078125}, {'val_loss': 7123.18310546875}, {'val_loss': 7123.2197265625}, {'val_loss': 7123.21630859375}, {'val_loss': 7123.2177734375}, {'val_loss': 7123.19189453125}, {'val_loss': 7123.17822265625}, {'val_loss': 7123.16552734375}, {'val_loss': 7123.17529296875}, {'val_loss': 7123.17578125}, {'val_loss': 7123.1904296875}, {'val_loss': 7123.2060546875}, {'val_loss': 7123.1943359375}, {'val_loss': 7123.20556640625}, {'val_loss': 7123.1962890625}, {'val_loss': 7123.18603515625}, {'val_loss': 7123.16796875}, {'val_loss': 7123.18115234375}, {'val_loss': 7123.1875}, {'val_loss': 7123.1708984375}, {'val_loss': 7123.1640625}, {'val_loss': 7123.13916015625}, {'val_loss': 7123.1416015625}, {'val_loss': 7123.13330078125}, {'val_loss': 7123.14404296875}, {'val_loss': 7123.14990234375}, {'val_loss': 7123.1396484375}, {'val_loss': 7123.13037109375}, {'val_loss': 7123.140625}, {'val_loss': 7123.13232421875}, {'val_loss': 7123.13525390625}, {'val_loss': 7123.12060546875}, {'val_loss': 7123.12060546875}, {'val_loss': 7123.10302734375}, {'val_loss': 7123.09375}, {'val_loss': 7123.0947265625}, {'val_loss': 7123.0908203125}, {'val_loss': 7123.06982421875}, {'val_loss': 7123.0908203125}, {'val_loss': 7123.09423828125}, {'val_loss': 7123.09619140625}, {'val_loss': 7123.09912109375}, {'val_loss': 7123.0888671875}, {'val_loss': 7123.09619140625}, {'val_loss': 7123.08349609375}, {'val_loss': 7123.07568359375}, {'val_loss': 7123.08203125}, {'val_loss': 7123.0703125}, {'val_loss': 7123.05908203125}, {'val_loss': 7123.04931640625}, {'val_loss': 7123.0517578125}, {'val_loss': 7123.05419921875}, {'val_loss': 7123.05322265625}, {'val_loss': 7123.04345703125}, {'val_loss': 7123.06689453125}, {'val_loss': 7123.04833984375}, {'val_loss': 7123.0458984375}, {'val_loss': 7123.05322265625}, {'val_loss': 7123.05517578125}, {'val_loss': 7123.04150390625}, {'val_loss': 7123.0556640625}, {'val_loss': 7123.04931640625}, {'val_loss': 7123.0419921875}, {'val_loss': 7123.0185546875}, {'val_loss': 7123.03076171875}, {'val_loss': 7123.0302734375}, {'val_loss': 7123.04052734375}, {'val_loss': 7123.04150390625}, {'val_loss': 7123.03955078125}, {'val_loss': 7123.0302734375}, {'val_loss': 7123.02294921875}, {'val_loss': 7123.0341796875}, {'val_loss': 7123.03662109375}, {'val_loss': 7123.02294921875}, {'val_loss': 7123.0283203125}, {'val_loss': 7123.02001953125}, {'val_loss': 7123.01904296875}, {'val_loss': 7123.00146484375}, {'val_loss': 7123.0068359375}, {'val_loss': 7122.9912109375}, {'val_loss': 7122.99365234375}, {'val_loss': 7122.99072265625}, {'val_loss': 7122.98974609375}, {'val_loss': 7122.984375}, {'val_loss': 7122.97607421875}, {'val_loss': 7122.98974609375}, {'val_loss': 7122.99169921875}, {'val_loss': 7122.98046875}, {'val_loss': 7122.984375}, {'val_loss': 7122.98779296875}, {'val_loss': 7122.98388671875}, {'val_loss': 7123.00048828125}, {'val_loss': 7123.02099609375}, {'val_loss': 7123.0322265625}, {'val_loss': 7123.02294921875}, {'val_loss': 7123.01611328125}, {'val_loss': 7122.98828125}, {'val_loss': 7122.97314453125}, {'val_loss': 7122.95751953125}, {'val_loss': 7122.9599609375}, {'val_loss': 7122.94287109375}, {'val_loss': 7122.94091796875}, {'val_loss': 7122.94140625}, {'val_loss': 7122.9306640625}, {'val_loss': 7122.90625}, {'val_loss': 7122.90380859375}, {'val_loss': 7122.90478515625}, {'val_loss': 7122.91845703125}, {'val_loss': 7122.9375}, {'val_loss': 7122.93017578125}, {'val_loss': 7122.91748046875}, {'val_loss': 7122.9248046875}, {'val_loss': 7122.93505859375}, {'val_loss': 7122.91845703125}, {'val_loss': 7122.92138671875}, {'val_loss': 7122.91064453125}, {'val_loss': 7122.90625}, {'val_loss': 7122.91650390625}, {'val_loss': 7122.8984375}, {'val_loss': 7122.88232421875}, {'val_loss': 7122.8603515625}, {'val_loss': 7122.86083984375}, {'val_loss': 7122.8603515625}, {'val_loss': 7122.8828125}, {'val_loss': 7122.87744140625}, {'val_loss': 7122.88037109375}, {'val_loss': 7122.8701171875}, {'val_loss': 7122.86376953125}, {'val_loss': 7122.86669921875}, {'val_loss': 7122.8740234375}, {'val_loss': 7122.86474609375}, {'val_loss': 7122.8623046875}, {'val_loss': 7122.859375}, {'val_loss': 7122.859375}, {'val_loss': 7122.8330078125}, {'val_loss': 7122.8056640625}, {'val_loss': 7122.80419921875}, {'val_loss': 7122.80126953125}, {'val_loss': 7122.8115234375}, {'val_loss': 7122.8251953125}, {'val_loss': 7122.82470703125}, {'val_loss': 7122.8251953125}, {'val_loss': 7122.82373046875}, {'val_loss': 7122.83544921875}, {'val_loss': 7122.82861328125}, {'val_loss': 7122.8173828125}, {'val_loss': 7122.81005859375}, {'val_loss': 7122.80810546875}, {'val_loss': 7122.81201171875}, {'val_loss': 7122.8251953125}, {'val_loss': 7122.8134765625}, {'val_loss': 7122.81689453125}, {'val_loss': 7122.8095703125}, {'val_loss': 7122.79931640625}, {'val_loss': 7122.80615234375}, {'val_loss': 7122.79150390625}, {'val_loss': 7122.79296875}, {'val_loss': 7122.79345703125}, {'val_loss': 7122.7822265625}, {'val_loss': 7122.7705078125}, {'val_loss': 7122.76904296875}, {'val_loss': 7122.7724609375}, {'val_loss': 7122.7783203125}, {'val_loss': 7122.74951171875}, {'val_loss': 7122.7470703125}, {'val_loss': 7122.74462890625}, {'val_loss': 7122.72802734375}, {'val_loss': 7122.73779296875}, {'val_loss': 7122.71875}, {'val_loss': 7122.7265625}, {'val_loss': 7122.74365234375}, {'val_loss': 7122.7255859375}, {'val_loss': 7122.73779296875}, {'val_loss': 7122.74853515625}, {'val_loss': 7122.73046875}, {'val_loss': 7122.73779296875}, {'val_loss': 7122.7421875}, {'val_loss': 7122.73583984375}, {'val_loss': 7122.74853515625}, {'val_loss': 7122.7431640625}, {'val_loss': 7122.73974609375}, {'val_loss': 7122.71923828125}, {'val_loss': 7122.7412109375}, {'val_loss': 7122.75390625}, {'val_loss': 7122.76123046875}, {'val_loss': 7122.74951171875}, {'val_loss': 7122.74560546875}, {'val_loss': 7122.7294921875}, {'val_loss': 7122.72900390625}, {'val_loss': 7122.7158203125}, {'val_loss': 7122.72509765625}, {'val_loss': 7122.7138671875}, {'val_loss': 7122.7138671875}, {'val_loss': 7122.70458984375}, {'val_loss': 7122.6943359375}, {'val_loss': 7122.7001953125}, {'val_loss': 7122.71630859375}, {'val_loss': 7122.7333984375}, {'val_loss': 7122.7275390625}, {'val_loss': 7122.734375}, {'val_loss': 7122.72802734375}, {'val_loss': 7122.70849609375}, {'val_loss': 7122.70068359375}, {'val_loss': 7122.69482421875}, {'val_loss': 7122.6748046875}, {'val_loss': 7122.67626953125}, {'val_loss': 7122.6689453125}, {'val_loss': 7122.66845703125}, {'val_loss': 7122.66845703125}, {'val_loss': 7122.6787109375}, {'val_loss': 7122.67236328125}, {'val_loss': 7122.66552734375}, {'val_loss': 7122.65283203125}, {'val_loss': 7122.64208984375}, {'val_loss': 7122.64111328125}, {'val_loss': 7122.6494140625}, {'val_loss': 7122.64306640625}, {'val_loss': 7122.640625}, {'val_loss': 7122.64208984375}, {'val_loss': 7122.65673828125}, {'val_loss': 7122.63330078125}, {'val_loss': 7122.64404296875}, {'val_loss': 7122.63623046875}, {'val_loss': 7122.63330078125}, {'val_loss': 7122.6396484375}, {'val_loss': 7122.63916015625}, {'val_loss': 7122.6396484375}, {'val_loss': 7122.6396484375}, {'val_loss': 7122.63916015625}, {'val_loss': 7122.6376953125}, {'val_loss': 7122.63916015625}, {'val_loss': 7122.63671875}, {'val_loss': 7122.6376953125}, {'val_loss': 7122.63720703125}, {'val_loss': 7122.63720703125}, {'val_loss': 7122.63720703125}, {'val_loss': 7122.63720703125}, {'val_loss': 7122.6357421875}, {'val_loss': 7122.63427734375}, {'val_loss': 7122.63330078125}, {'val_loss': 7122.6328125}, {'val_loss': 7122.6318359375}, {'val_loss': 7122.6318359375}, {'val_loss': 7122.63232421875}, {'val_loss': 7122.6318359375}, {'val_loss': 7122.63134765625}, {'val_loss': 7122.62939453125}, {'val_loss': 7122.62890625}, {'val_loss': 7122.62841796875}, {'val_loss': 7122.62744140625}, {'val_loss': 7122.62744140625}, {'val_loss': 7122.6279296875}, {'val_loss': 7122.6279296875}, {'val_loss': 7122.6259765625}, {'val_loss': 7122.62548828125}, {'val_loss': 7122.62744140625}, {'val_loss': 7122.625}, {'val_loss': 7122.62744140625}, {'val_loss': 7122.6259765625}, {'val_loss': 7122.62548828125}, {'val_loss': 7122.625}, {'val_loss': 7122.62451171875}, {'val_loss': 7122.62451171875}, {'val_loss': 7122.62255859375}, {'val_loss': 7122.625}, {'val_loss': 7122.6240234375}, {'val_loss': 7122.62451171875}, {'val_loss': 7122.62451171875}, {'val_loss': 7122.62451171875}, {'val_loss': 7122.62451171875}, {'val_loss': 7122.62451171875}, {'val_loss': 7122.62255859375}, {'val_loss': 7122.6220703125}, {'val_loss': 7122.62109375}, {'val_loss': 7122.62109375}, {'val_loss': 7122.62109375}, {'val_loss': 7122.6201171875}, {'val_loss': 7122.61962890625}, {'val_loss': 7122.6201171875}, {'val_loss': 7122.61962890625}, {'val_loss': 7122.61865234375}, {'val_loss': 7122.61669921875}, {'val_loss': 7122.61474609375}, {'val_loss': 7122.61474609375}, {'val_loss': 7122.61376953125}, {'val_loss': 7122.6142578125}, {'val_loss': 7122.61376953125}, {'val_loss': 7122.61572265625}, {'val_loss': 7122.61328125}, {'val_loss': 7122.61328125}, {'val_loss': 7122.61376953125}, {'val_loss': 7122.61474609375}, {'val_loss': 7122.61376953125}, {'val_loss': 7122.61474609375}, {'val_loss': 7122.61279296875}, {'val_loss': 7122.61279296875}, {'val_loss': 7122.6123046875}, {'val_loss': 7122.6123046875}, {'val_loss': 7122.6123046875}, {'val_loss': 7122.6123046875}, {'val_loss': 7122.6123046875}, {'val_loss': 7122.61181640625}, {'val_loss': 7122.61083984375}, {'val_loss': 7122.61181640625}, {'val_loss': 7122.61083984375}, {'val_loss': 7122.6103515625}, {'val_loss': 7122.61181640625}, {'val_loss': 7122.6103515625}, {'val_loss': 7122.609375}, {'val_loss': 7122.60791015625}, {'val_loss': 7122.60791015625}, {'val_loss': 7122.6083984375}, {'val_loss': 7122.6083984375}, {'val_loss': 7122.6064453125}, {'val_loss': 7122.60400390625}, {'val_loss': 7122.6044921875}, {'val_loss': 7122.60302734375}, {'val_loss': 7122.60302734375}, {'val_loss': 7122.6025390625}, {'val_loss': 7122.6044921875}, {'val_loss': 7122.60400390625}, {'val_loss': 7122.6044921875}, {'val_loss': 7122.60302734375}, {'val_loss': 7122.6005859375}, {'val_loss': 7122.60205078125}, {'val_loss': 7122.6015625}, {'val_loss': 7122.60107421875}, {'val_loss': 7122.6005859375}, {'val_loss': 7122.6015625}, {'val_loss': 7122.60205078125}, {'val_loss': 7122.6025390625}, {'val_loss': 7122.60205078125}, {'val_loss': 7122.6025390625}, {'val_loss': 7122.60205078125}, {'val_loss': 7122.6015625}, {'val_loss': 7122.6025390625}, {'val_loss': 7122.60302734375}, {'val_loss': 7122.60302734375}, {'val_loss': 7122.6015625}, {'val_loss': 7122.60107421875}, {'val_loss': 7122.6044921875}, {'val_loss': 7122.60302734375}, {'val_loss': 7122.60205078125}, {'val_loss': 7122.6025390625}, {'val_loss': 7122.6025390625}, {'val_loss': 7122.6015625}, {'val_loss': 7122.6005859375}, {'val_loss': 7122.6015625}, {'val_loss': 7122.60009765625}, {'val_loss': 7122.60009765625}, {'val_loss': 7122.59912109375}, {'val_loss': 7122.59912109375}, {'val_loss': 7122.59912109375}, {'val_loss': 7122.59814453125}, {'val_loss': 7122.59814453125}, {'val_loss': 7122.59814453125}, {'val_loss': 7122.59814453125}, {'val_loss': 7122.59912109375}, {'val_loss': 7122.59814453125}, {'val_loss': 7122.59814453125}, {'val_loss': 7122.59765625}, {'val_loss': 7122.59716796875}, {'val_loss': 7122.5966796875}, {'val_loss': 7122.59716796875}, {'val_loss': 7122.5966796875}, {'val_loss': 7122.59521484375}, {'val_loss': 7122.59521484375}, {'val_loss': 7122.59375}, {'val_loss': 7122.59375}, {'val_loss': 7122.59423828125}, {'val_loss': 7122.5947265625}, {'val_loss': 7122.59521484375}, {'val_loss': 7122.59375}, {'val_loss': 7122.59326171875}, {'val_loss': 7122.59228515625}, {'val_loss': 7122.59130859375}, {'val_loss': 7122.59326171875}, {'val_loss': 7122.59228515625}, {'val_loss': 7122.59228515625}, {'val_loss': 7122.59033203125}, {'val_loss': 7122.58935546875}, {'val_loss': 7122.58984375}, {'val_loss': 7122.5888671875}, {'val_loss': 7122.58935546875}, {'val_loss': 7122.58837890625}, {'val_loss': 7122.5869140625}, {'val_loss': 7122.58837890625}, {'val_loss': 7122.58935546875}, {'val_loss': 7122.5888671875}, {'val_loss': 7122.58837890625}, {'val_loss': 7122.58642578125}, {'val_loss': 7122.58740234375}, {'val_loss': 7122.58740234375}, {'val_loss': 7122.5869140625}, {'val_loss': 7122.5869140625}, {'val_loss': 7122.5869140625}, {'val_loss': 7122.5869140625}, {'val_loss': 7122.5859375}, {'val_loss': 7122.58447265625}, {'val_loss': 7122.58447265625}, {'val_loss': 7122.58447265625}, {'val_loss': 7122.5830078125}, {'val_loss': 7122.58251953125}, {'val_loss': 7122.58154296875}, {'val_loss': 7122.5791015625}, {'val_loss': 7122.57958984375}, {'val_loss': 7122.57861328125}, {'val_loss': 7122.578125}, {'val_loss': 7122.5771484375}, {'val_loss': 7122.57470703125}, {'val_loss': 7122.57568359375}, {'val_loss': 7122.57666015625}, {'val_loss': 7122.5771484375}, {'val_loss': 7122.5771484375}, {'val_loss': 7122.57568359375}, {'val_loss': 7122.57666015625}, {'val_loss': 7122.57568359375}, {'val_loss': 7122.5751953125}, {'val_loss': 7122.57470703125}, {'val_loss': 7122.57470703125}, {'val_loss': 7122.57470703125}, {'val_loss': 7122.5732421875}, {'val_loss': 7122.57373046875}, {'val_loss': 7122.57275390625}, {'val_loss': 7122.57275390625}, {'val_loss': 7122.57177734375}, {'val_loss': 7122.5712890625}, {'val_loss': 7122.5712890625}, {'val_loss': 7122.5712890625}, {'val_loss': 7122.5703125}, {'val_loss': 7122.57080078125}, {'val_loss': 7122.5693359375}, {'val_loss': 7122.56884765625}, {'val_loss': 7122.56884765625}, {'val_loss': 7122.5693359375}, {'val_loss': 7122.56787109375}, {'val_loss': 7122.5693359375}, {'val_loss': 7122.56884765625}, {'val_loss': 7122.56884765625}, {'val_loss': 7122.5693359375}, {'val_loss': 7122.56787109375}, {'val_loss': 7122.5673828125}, {'val_loss': 7122.5673828125}, {'val_loss': 7122.56689453125}, {'val_loss': 7122.56591796875}, {'val_loss': 7122.56591796875}, {'val_loss': 7122.56591796875}, {'val_loss': 7122.56494140625}, {'val_loss': 7122.5654296875}, {'val_loss': 7122.56298828125}, {'val_loss': 7122.56201171875}, {'val_loss': 7122.5625}, {'val_loss': 7122.56201171875}, {'val_loss': 7122.56201171875}, {'val_loss': 7122.5615234375}, {'val_loss': 7122.5615234375}, {'val_loss': 7122.55908203125}, {'val_loss': 7122.56005859375}, {'val_loss': 7122.55810546875}, {'val_loss': 7122.55859375}, {'val_loss': 7122.55810546875}, {'val_loss': 7122.55908203125}, {'val_loss': 7122.56103515625}, {'val_loss': 7122.56103515625}, {'val_loss': 7122.56103515625}, {'val_loss': 7122.56103515625}, {'val_loss': 7122.56103515625}, {'val_loss': 7122.56005859375}, {'val_loss': 7122.5595703125}, {'val_loss': 7122.55810546875}, {'val_loss': 7122.55810546875}, {'val_loss': 7122.55810546875}, {'val_loss': 7122.55810546875}, {'val_loss': 7122.55712890625}, {'val_loss': 7122.55615234375}, {'val_loss': 7122.5556640625}, {'val_loss': 7122.55517578125}, {'val_loss': 7122.5546875}, {'val_loss': 7122.55322265625}, {'val_loss': 7122.55322265625}, {'val_loss': 7122.55322265625}, {'val_loss': 7122.55419921875}, {'val_loss': 7122.55322265625}, {'val_loss': 7122.5537109375}, {'val_loss': 7122.5546875}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'losses')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "[result] + history1 + history2 + history3 + history4 + history5\n",
    "print(val_loss)\n",
    "val_loss_list = [vl['val_loss'] for vl in val_loss]\n",
    "\n",
    "plt.plot(val_loss_list, 'r+')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYeOWp0ZyxsX"
   },
   "source": [
    "Let's log the final validation loss to Jovian and commit the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "cCbFzk4nyxsY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Metrics logged.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.log_metrics(val_loss=val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "p6DdWyesyxsn"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"nixkjadhav007/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/nixkjadhav007/02-insurance-linear-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/nixkjadhav007/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDCnb_kvyxst"
   },
   "source": [
    "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl2hRTNtyxsu"
   },
   "source": [
    "## Step 5: Make predictions using the trained model\n",
    "\n",
    "**Q: Complete the following function definition to make predictions on a single input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "-sDt4tr0yxsv"
   },
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)             # fill this\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "oZJEaK5myxs4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([24.0000,  0.0000, 21.5460,  0.0000,  1.0000])\n",
      "Target: tensor([15591.9229])\n",
      "Prediction: tensor([4767.1357])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "l90fGoA_yxs-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([41.0000,  1.0000, 33.8100,  2.0000,  0.0000])\n",
      "Target: tensor([7357.2783])\n",
      "Prediction: tensor([8455.2324])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "I1b-JjvWyxtC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([18.0000,  1.0000, 24.1395,  0.0000,  0.0000])\n",
      "Target: tensor([1823.8878])\n",
      "Prediction: tensor([2798.2485])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LozSKEYyyxtH"
   },
   "source": [
    "Are you happy with your model's predictions? Try to improve them further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upPuEhfKyxtI"
   },
   "source": [
    "## (Optional) Step 6: Try another dataset & blog about it\n",
    "\n",
    "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to clean up & replicate this notebook (or [this one](https://jovian.ml/aakashns/housing-linear-minimal), or [this one](https://jovian.ml/aakashns/mnist-logistic-minimal) ) for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patters in machine learning from problem-specific details.\n",
    "\n",
    "Here are some sources to find good datasets:\n",
    "\n",
    "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
    "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
    "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
    "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
    "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
    "\n",
    "- Interesting title & subtitle\n",
    "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
    "- Downloading & exploring the data\n",
    "- Preparing the data for training\n",
    "- Creating a model using PyTorch\n",
    "- Training the model to fit the data\n",
    "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
    "- Making predictions using the model\n",
    "\n",
    "As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n",
    "\n",
    "Don't forget to share your work on the forum: https://jovian.ml/forum/t/share-your-work-here-assignment-2/4931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9YgOeDwyxtJ"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"nixkjadhav007/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/nixkjadhav007/02-insurance-linear-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)\n",
    "jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4EXUXXmyxtO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
